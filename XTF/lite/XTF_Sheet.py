#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
XTF_Sheet (Excel To Feishu Sheet) - æœ¬åœ°è¡¨æ ¼åŒæ­¥åˆ°é£ä¹¦ç”µå­è¡¨æ ¼å·¥å…·
æ”¯æŒå››ç§åŒæ­¥æ¨¡å¼ï¼šå…¨é‡ã€å¢é‡ã€è¦†ç›–ã€å…‹éš†
é’ˆå¯¹é£ä¹¦ç”µå­è¡¨æ ¼APIä¼˜åŒ–çš„ä¼ä¸šçº§æ•°æ®åŒæ­¥å·¥å…·
"""

import pandas as pd
import requests
import yaml
import time
import logging
import argparse
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, Dict, Any, List
from dataclasses import dataclass
from enum import Enum
import sys
import hashlib

# å¯¼å…¥æ™ºèƒ½Excelè¯»å–æ¨¡å—
sys.path.insert(0, str(Path(__file__).parent.parent))
from utils.excel_reader import smart_read_excel, print_engine_info


class SyncMode(Enum):
    """åŒæ­¥æ¨¡å¼æšä¸¾"""
    FULL = "full"          # å…¨é‡åŒæ­¥ï¼šå·²å­˜åœ¨çš„æ›´æ–°ï¼Œä¸å­˜åœ¨çš„æ–°å¢
    INCREMENTAL = "incremental"  # å¢é‡åŒæ­¥ï¼šåªæ–°å¢ä¸å­˜åœ¨çš„è®°å½•
    OVERWRITE = "overwrite"     # è¦†ç›–åŒæ­¥ï¼šåˆ é™¤å·²å­˜åœ¨çš„ï¼Œç„¶åæ–°å¢å…¨éƒ¨
    CLONE = "clone"             # å…‹éš†åŒæ­¥ï¼šæ¸…ç©ºå…¨éƒ¨ï¼Œç„¶åæ–°å¢å…¨éƒ¨


@dataclass
class SyncConfig:
    """åŒæ­¥é…ç½®"""
    # åŸºç¡€é…ç½®
    file_path: str
    app_id: str
    app_secret: str
    
    # ç”µå­è¡¨æ ¼é…ç½®
    spreadsheet_token: str
    sheet_id: str
    start_row: int = 1  # å¼€å§‹è¡Œå·ï¼ˆ1-basedï¼‰
    start_column: str = "A"  # å¼€å§‹åˆ—å·
    
    # åŒæ­¥è®¾ç½®
    sync_mode: SyncMode = SyncMode.FULL
    index_column: Optional[str] = None  # ç´¢å¼•åˆ—åï¼Œç”¨äºè®°å½•æ¯”å¯¹
    
    # æ€§èƒ½è®¾ç½®
    batch_size: int = 1000  # æ‰¹å¤„ç†å¤§å°
    rate_limit_delay: float = 0.1  # æ¥å£è°ƒç”¨é—´éš”
    max_retries: int = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
    
    # æ—¥å¿—è®¾ç½®
    log_level: str = "INFO"
    
    def __post_init__(self):
        if isinstance(self.sync_mode, str):
            self.sync_mode = SyncMode(self.sync_mode)


class RateLimiter:
    """æ¥å£é¢‘ç‡é™åˆ¶å™¨"""
    def __init__(self, delay: float = 0.1):
        self.delay = delay
        self.last_call = 0
    
    def wait(self):
        """ç­‰å¾…ä»¥éµå®ˆé¢‘ç‡é™åˆ¶"""
        current_time = time.time()
        time_since_last = current_time - self.last_call
        if time_since_last < self.delay:
            time.sleep(self.delay - time_since_last)
        self.last_call = time.time()


class RetryableAPIClient:
    """å¯é‡è¯•çš„APIå®¢æˆ·ç«¯"""
    def __init__(self, max_retries: int = 3, rate_limiter: Optional[RateLimiter] = None):
        self.max_retries = max_retries
        self.rate_limiter = rate_limiter or RateLimiter()
        self.logger = logging.getLogger(__name__)
    
    def call_api(self, method: str, url: str, **kwargs) -> requests.Response:
        """è°ƒç”¨APIå¹¶å¤„ç†é‡è¯•"""
        for attempt in range(self.max_retries + 1):
            try:
                self.rate_limiter.wait()
                
                response = requests.request(method, url, timeout=60, **kwargs)
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•
                if response.status_code == 429:  # é¢‘ç‡é™åˆ¶
                    if attempt < self.max_retries:
                        wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                        self.logger.warning(f"é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                        time.sleep(wait_time)
                        continue
                
                if response.status_code >= 500:  # æœåŠ¡å™¨é”™è¯¯
                    if attempt < self.max_retries:
                        wait_time = 2 ** attempt
                        self.logger.warning(f"æœåŠ¡å™¨é”™è¯¯ {response.status_code}ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                        time.sleep(wait_time)
                        continue
                
                return response
                
            except requests.exceptions.RequestException as e:
                if attempt < self.max_retries:
                    wait_time = 2 ** attempt
                    self.logger.warning(f"è¯·æ±‚å¼‚å¸¸ {e}ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    continue
                raise
        
        raise Exception(f"APIè°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯• {self.max_retries} æ¬¡")


class FeishuSheetAPIClient:
    """é£ä¹¦ç”µå­è¡¨æ ¼APIå®¢æˆ·ç«¯"""
    def __init__(self, config: SyncConfig):
        self.config = config
        self.tenant_access_token = None
        self.token_expires_at = None
        self.api_client = RetryableAPIClient(
            max_retries=config.max_retries,
            rate_limiter=RateLimiter(config.rate_limit_delay)
        )
        self.logger = logging.getLogger(__name__)
    
    def get_tenant_access_token(self) -> str:
        """è·å–ç§Ÿæˆ·è®¿é—®ä»¤ç‰Œ"""
        # æ£€æŸ¥tokenæ˜¯å¦è¿‡æœŸ
        if (self.tenant_access_token and self.token_expires_at and 
            datetime.now() < self.token_expires_at - timedelta(minutes=5)):
            return self.tenant_access_token
        
        url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
        headers = {"Content-Type": "application/json; charset=utf-8"}
        data = {
            "app_id": self.config.app_id,
            "app_secret": self.config.app_secret
        }
        
        response = self.api_client.call_api("POST", url, headers=headers, json=data)
        
        try:
            result = response.json()
        except ValueError as e:
            raise Exception(f"è·å–è®¿é—®ä»¤ç‰Œå“åº”è§£æå¤±è´¥: {e}, HTTPçŠ¶æ€ç : {response.status_code}")
        
        if result.get("code") != 0:
            error_msg = result.get('msg', 'æœªçŸ¥é”™è¯¯')
            raise Exception(f"è·å–è®¿é—®ä»¤ç‰Œå¤±è´¥: é”™è¯¯ç  {result.get('code')}, é”™è¯¯ä¿¡æ¯: {error_msg}")
        
        self.tenant_access_token = result["tenant_access_token"]
        # è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆæå‰5åˆ†é’Ÿåˆ·æ–°ï¼‰
        expires_in = result.get("expire", 7200)
        self.token_expires_at = datetime.now() + timedelta(seconds=expires_in)
        
        self.logger.info("æˆåŠŸè·å–ç§Ÿæˆ·è®¿é—®ä»¤ç‰Œ")
        return self.tenant_access_token
    
    def get_auth_headers(self) -> Dict[str, str]:
        """è·å–è®¤è¯å¤´"""
        token = self.get_tenant_access_token()
        return {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json; charset=utf-8"
        }
    
    def get_sheet_info(self, spreadsheet_token: str) -> Dict[str, Any]:
        """è·å–ç”µå­è¡¨æ ¼ä¿¡æ¯"""
        url = f"https://open.feishu.cn/open-apis/sheets/v3/spreadsheets/{spreadsheet_token}"
        headers = self.get_auth_headers()
        
        response = self.api_client.call_api("GET", url, headers=headers)
        
        try:
            result = response.json()
        except ValueError as e:
            raise Exception(f"è·å–ç”µå­è¡¨æ ¼ä¿¡æ¯å“åº”è§£æå¤±è´¥: {e}, HTTPçŠ¶æ€ç : {response.status_code}")
        
        if result.get("code") != 0:
            error_msg = result.get('msg', 'æœªçŸ¥é”™è¯¯')
            raise Exception(f"è·å–ç”µå­è¡¨æ ¼ä¿¡æ¯å¤±è´¥: é”™è¯¯ç  {result.get('code')}, é”™è¯¯ä¿¡æ¯: {error_msg}")
        
        return result.get("data", {})
    
    def get_sheet_data(self, spreadsheet_token: str, range_str: str) -> List[List[Any]]:
        """è¯»å–ç”µå­è¡¨æ ¼æ•°æ®"""
        url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{spreadsheet_token}/values/{range_str}"
        headers = self.get_auth_headers()
        
        response = self.api_client.call_api("GET", url, headers=headers)
        
        try:
            result = response.json()
        except ValueError as e:
            raise Exception(f"è¯»å–ç”µå­è¡¨æ ¼æ•°æ®å“åº”è§£æå¤±è´¥: {e}, HTTPçŠ¶æ€ç : {response.status_code}")
        
        if result.get("code") != 0:
            error_msg = result.get('msg', 'æœªçŸ¥é”™è¯¯')
            raise Exception(f"è¯»å–ç”µå­è¡¨æ ¼æ•°æ®å¤±è´¥: é”™è¯¯ç  {result.get('code')}, é”™è¯¯ä¿¡æ¯: {error_msg}")
        
        data = result.get("data", {})
        value_range = data.get("valueRange", {})
        return value_range.get("values", [])
    
    def write_sheet_data(self, spreadsheet_token: str, range_str: str, values: List[List[Any]]) -> bool:
        """å†™å…¥ç”µå­è¡¨æ ¼æ•°æ®"""
        url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{spreadsheet_token}/values"
        headers = self.get_auth_headers()
        
        data = {
            "valueRange": {
                "range": range_str,
                "values": values
            }
        }
        
        response = self.api_client.call_api("PUT", url, headers=headers, json=data)
        
        try:
            result = response.json()
        except ValueError as e:
            self.logger.error(f"å†™å…¥ç”µå­è¡¨æ ¼æ•°æ®å“åº”è§£æå¤±è´¥: {e}, HTTPçŠ¶æ€ç : {response.status_code}")
            self.logger.debug(f"å“åº”å†…å®¹: {response.text[:500]}")
            return False
        
        if result.get("code") != 0:
            error_msg = result.get('msg', 'æœªçŸ¥é”™è¯¯')
            self.logger.error(f"å†™å…¥ç”µå­è¡¨æ ¼æ•°æ®å¤±è´¥: é”™è¯¯ç  {result.get('code')}, é”™è¯¯ä¿¡æ¯: {error_msg}")
            self.logger.debug(f"APIå“åº”: {result}")
            return False
        
        self.logger.debug(f"æˆåŠŸå†™å…¥ {len(values)} è¡Œæ•°æ®")
        return True
    
    def append_sheet_data(self, spreadsheet_token: str, range_str: str, values: List[List[Any]]) -> bool:
        """è¿½åŠ ç”µå­è¡¨æ ¼æ•°æ®"""
        url = f"https://open.feishu.cn/open-apis/sheets/v2/spreadsheets/{spreadsheet_token}/values_append"
        headers = self.get_auth_headers()
        
        data = {
            "valueRange": {
                "range": range_str,
                "values": values
            }
        }
        
        response = self.api_client.call_api("POST", url, headers=headers, json=data)
        
        try:
            result = response.json()
        except ValueError as e:
            self.logger.error(f"è¿½åŠ ç”µå­è¡¨æ ¼æ•°æ®å“åº”è§£æå¤±è´¥: {e}, HTTPçŠ¶æ€ç : {response.status_code}")
            self.logger.debug(f"å“åº”å†…å®¹: {response.text[:500]}")
            return False
        
        if result.get("code") != 0:
            error_msg = result.get('msg', 'æœªçŸ¥é”™è¯¯')
            self.logger.error(f"è¿½åŠ ç”µå­è¡¨æ ¼æ•°æ®å¤±è´¥: é”™è¯¯ç  {result.get('code')}, é”™è¯¯ä¿¡æ¯: {error_msg}")
            self.logger.debug(f"APIå“åº”: {result}")
            return False
        
        self.logger.debug(f"æˆåŠŸè¿½åŠ  {len(values)} è¡Œæ•°æ®")
        return True
    
    def clear_sheet_data(self, spreadsheet_token: str, range_str: str) -> bool:
        """æ¸…ç©ºç”µå­è¡¨æ ¼æ•°æ®"""
        # é€šè¿‡å†™å…¥ç©ºæ•°æ®æ¥æ¸…ç©º
        return self.write_sheet_data(spreadsheet_token, range_str, [[]])


class XTFSheetSyncEngine:
    """XTFç”µå­è¡¨æ ¼åŒæ­¥å¼•æ“"""
    
    def __init__(self, config: SyncConfig):
        """åˆå§‹åŒ–åŒæ­¥å¼•æ“"""
        self.config = config
        self.api_client = FeishuSheetAPIClient(config)
        self.setup_logging()
        self.logger = logging.getLogger(__name__)
        
        # æ·»åŠ è½¬æ¢ç»Ÿè®¡
        self.conversion_stats = {
            'success': 0,
            'failed': 0,
            'warnings': []
        }
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_dir = Path('logs')
        log_dir.mkdir(exist_ok=True)
        
        log_file = log_dir / f"xtf_sheet_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        # æ¸…é™¤å·²æœ‰çš„å¤„ç†å™¨
        logging.getLogger().handlers.clear()
        
        level = getattr(logging, self.config.log_level.upper(), logging.INFO)
        logging.basicConfig(
            level=level,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
    
    def column_number_to_letter(self, col_num: int) -> str:
        """å°†åˆ—å·è½¬æ¢ä¸ºå­—æ¯ï¼ˆ1->A, 2->B, ..., 26->Z, 27->AAï¼‰"""
        result = ""
        while col_num > 0:
            col_num -= 1
            result = chr(65 + col_num % 26) + result
            col_num //= 26
        return result
    
    def column_letter_to_number(self, col_letter: str) -> int:
        """å°†åˆ—å­—æ¯è½¬æ¢ä¸ºæ•°å­—ï¼ˆA->1, B->2, ..., Z->26, AA->27ï¼‰"""
        result = 0
        for char in col_letter:
            result = result * 26 + (ord(char) - ord('A') + 1)
        return result
    
    def get_range_string(self, start_row: int, start_col: str, end_row: int, end_col: str) -> str:
        """ç”ŸæˆèŒƒå›´å­—ç¬¦ä¸²"""
        return f"{self.config.sheet_id}!{start_col}{start_row}:{end_col}{end_row}"
    
    def df_to_values(self, df: pd.DataFrame, include_headers: bool = True) -> List[List[Any]]:
        """å°†DataFrameè½¬æ¢ä¸ºç”µå­è¡¨æ ¼å€¼æ ¼å¼"""
        values = []
        
        # æ·»åŠ è¡¨å¤´
        if include_headers:
            values.append(df.columns.tolist())
        
        # æ·»åŠ æ•°æ®è¡Œ
        for _, row in df.iterrows():
            row_values = []
            for value in row:
                if pd.isnull(value):
                    row_values.append("")
                else:
                    # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æˆ–åŸºæœ¬ç±»å‹
                    if isinstance(value, (int, float)):
                        row_values.append(value)
                    elif isinstance(value, bool):
                        row_values.append(value)
                    else:
                        row_values.append(str(value))
            values.append(row_values)
        
        return values
    
    def values_to_df(self, values: List[List[Any]]) -> pd.DataFrame:
        """å°†ç”µå­è¡¨æ ¼å€¼æ ¼å¼è½¬æ¢ä¸ºDataFrame"""
        if not values:
            return pd.DataFrame()
        
        # ç¬¬ä¸€è¡Œä½œä¸ºè¡¨å¤´
        headers = values[0] if values else []
        data_rows = values[1:] if len(values) > 1 else []
        
        # åˆ›å»ºDataFrame
        if data_rows:
            df = pd.DataFrame(data_rows, columns=headers)
        else:
            df = pd.DataFrame(columns=headers)
        
        return df
    
    def get_index_value_hash(self, row: pd.Series) -> Optional[str]:
        """è®¡ç®—ç´¢å¼•å€¼çš„å“ˆå¸Œ"""
        if self.config.index_column and self.config.index_column in row:
            value = str(row[self.config.index_column])
            return hashlib.md5(value.encode('utf-8')).hexdigest()
        return None
    
    def build_data_index(self, df: pd.DataFrame) -> Dict[str, int]:
        """æ„å»ºæ•°æ®ç´¢å¼•ï¼ˆå“ˆå¸Œ -> è¡Œå·ï¼‰"""
        index = {}
        if not self.config.index_column:
            return index
        
        for idx, row in df.iterrows():
            index_hash = self.get_index_value_hash(row)
            if index_hash:
                index[index_hash] = idx
        
        return index
    
    def get_current_sheet_data(self) -> pd.DataFrame:
        """è·å–å½“å‰ç”µå­è¡¨æ ¼æ•°æ®"""
        # å…ˆè·å–ä¸€ä¸ªè¾ƒå¤§çš„èŒƒå›´æ¥ç¡®å®šå®é™…æ•°æ®èŒƒå›´
        range_str = f"{self.config.sheet_id}!A1:ZZ10000"
        
        try:
            values = self.api_client.get_sheet_data(self.config.spreadsheet_token, range_str)
            return self.values_to_df(values)
        except Exception as e:
            self.logger.warning(f"è·å–å½“å‰ç”µå­è¡¨æ ¼æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def sync_full(self, df: pd.DataFrame) -> bool:
        """å…¨é‡åŒæ­¥ï¼šæ›´æ–°å­˜åœ¨çš„ï¼Œæ–°å¢ä¸å­˜åœ¨çš„"""
        self.logger.info("å¼€å§‹å…¨é‡åŒæ­¥...")
        
        if not self.config.index_column:
            self.logger.warning("æœªæŒ‡å®šç´¢å¼•åˆ—ï¼Œå°†æ‰§è¡Œå®Œå…¨è¦†ç›–æ“ä½œ")
            return self.sync_clone(df)
        
        # è·å–ç°æœ‰æ•°æ®
        current_df = self.get_current_sheet_data()
        
        if current_df.empty:
            self.logger.info("ç”µå­è¡¨æ ¼ä¸ºç©ºï¼Œæ‰§è¡Œæ–°å¢æ“ä½œ")
            return self.sync_clone(df)
        
        # æ„å»ºç´¢å¼•
        current_index = self.build_data_index(current_df)
        
        # åˆ†ç±»æ•°æ®
        update_rows = []
        new_rows = []
        
        for _, row in df.iterrows():
            index_hash = self.get_index_value_hash(row)
            if index_hash and index_hash in current_index:
                # æ›´æ–°ç°æœ‰è¡Œ
                current_row_idx = current_index[index_hash]
                update_rows.append((current_row_idx, row))
            else:
                # æ–°å¢è¡Œ
                new_rows.append(row)
        
        self.logger.info(f"å…¨é‡åŒæ­¥è®¡åˆ’: æ›´æ–° {len(update_rows)} è¡Œï¼Œæ–°å¢ {len(new_rows)} è¡Œ")
        
        # æ‰§è¡Œæ›´æ–°
        success = True
        if update_rows:
            # æ›´æ–°ç°æœ‰è¡Œ
            updated_df = current_df.copy()
            for current_row_idx, new_row in update_rows:
                for col in df.columns:
                    if col in updated_df.columns:
                        updated_df.iloc[current_row_idx][col] = new_row[col]
            
            # å†™å…¥æ›´æ–°åçš„æ•°æ®
            values = self.df_to_values(updated_df)
            end_col = self.column_number_to_letter(len(updated_df.columns))
            range_str = self.get_range_string(1, "A", len(values), end_col)
            success = self.api_client.write_sheet_data(self.config.spreadsheet_token, range_str, values)
        
        # è¿½åŠ æ–°è¡Œ
        if new_rows and success:
            new_df = pd.DataFrame(new_rows)
            new_values = self.df_to_values(new_df, include_headers=False)
            
            if new_values:
                # è®¡ç®—è¿½åŠ çš„èµ·å§‹è¡Œ
                start_row = len(current_df) + 2  # +1 for header, +1 for next row
                end_col_letter = self.column_number_to_letter(len(df.columns))
                range_str = self.get_range_string(start_row, "A", start_row + len(new_values) - 1, end_col_letter)
                success = self.api_client.append_sheet_data(self.config.spreadsheet_token, range_str, new_values)
        
        return success
    
    def sync_incremental(self, df: pd.DataFrame) -> bool:
        """å¢é‡åŒæ­¥ï¼šåªæ–°å¢ä¸å­˜åœ¨çš„è®°å½•"""
        self.logger.info("å¼€å§‹å¢é‡åŒæ­¥...")
        
        if not self.config.index_column:
            self.logger.warning("æœªæŒ‡å®šç´¢å¼•åˆ—ï¼Œå°†æ–°å¢å…¨éƒ¨æ•°æ®")
            # è¿½åŠ æ‰€æœ‰æ•°æ®
            values = self.df_to_values(df)
            range_str = f"{self.config.sheet_id}!A:A"  # è®©ç³»ç»Ÿè‡ªåŠ¨ç¡®å®šè¿½åŠ ä½ç½®
            return self.api_client.append_sheet_data(self.config.spreadsheet_token, range_str, values)
        
        # è·å–ç°æœ‰æ•°æ®
        current_df = self.get_current_sheet_data()
        
        if current_df.empty:
            self.logger.info("ç”µå­è¡¨æ ¼ä¸ºç©ºï¼Œæ–°å¢å…¨éƒ¨æ•°æ®")
            return self.sync_clone(df)
        
        # æ„å»ºç´¢å¼•
        current_index = self.build_data_index(current_df)
        
        # ç­›é€‰éœ€è¦æ–°å¢çš„è®°å½•
        new_rows = []
        for _, row in df.iterrows():
            index_hash = self.get_index_value_hash(row)
            if not index_hash or index_hash not in current_index:
                new_rows.append(row)
        
        self.logger.info(f"å¢é‡åŒæ­¥è®¡åˆ’: æ–°å¢ {len(new_rows)} è¡Œ")
        
        if new_rows:
            new_df = pd.DataFrame(new_rows)
            new_values = self.df_to_values(new_df, include_headers=False)
            
            # è¿½åŠ æ–°æ•°æ®
            range_str = f"{self.config.sheet_id}!A:A"  # è®©ç³»ç»Ÿè‡ªåŠ¨ç¡®å®šè¿½åŠ ä½ç½®
            return self.api_client.append_sheet_data(self.config.spreadsheet_token, range_str, new_values)
        else:
            self.logger.info("æ²¡æœ‰æ–°è®°å½•éœ€è¦åŒæ­¥")
            return True
    
    def sync_overwrite(self, df: pd.DataFrame) -> bool:
        """è¦†ç›–åŒæ­¥ï¼šåˆ é™¤å·²å­˜åœ¨çš„ï¼Œç„¶åæ–°å¢å…¨éƒ¨"""
        self.logger.info("å¼€å§‹è¦†ç›–åŒæ­¥...")
        
        if not self.config.index_column:
            self.logger.error("è¦†ç›–åŒæ­¥æ¨¡å¼éœ€è¦æŒ‡å®šç´¢å¼•åˆ—")
            return False
        
        # è·å–ç°æœ‰æ•°æ®
        current_df = self.get_current_sheet_data()
        
        if current_df.empty:
            self.logger.info("ç”µå­è¡¨æ ¼ä¸ºç©ºï¼Œæ‰§è¡Œæ–°å¢æ“ä½œ")
            return self.sync_clone(df)
        
        # æ‰¾å‡ºéœ€è¦åˆ é™¤çš„è®°å½•å¹¶æ„å»ºæ–°çš„æ•°æ®é›†
        new_df_rows = []
        deleted_count = 0
        
        # ä¿ç•™ä¸åœ¨æ–°æ•°æ®ä¸­çš„ç°æœ‰è®°å½•
        for _, row in current_df.iterrows():
            index_hash = self.get_index_value_hash(row)
            if index_hash:
                # æ£€æŸ¥æ˜¯å¦åœ¨æ–°æ•°æ®ä¸­
                found_in_new = False
                for _, new_row in df.iterrows():
                    new_index_hash = self.get_index_value_hash(new_row)
                    if new_index_hash == index_hash:
                        found_in_new = True
                        break
                
                if not found_in_new:
                    new_df_rows.append(row)
                else:
                    deleted_count += 1
        
        # æ·»åŠ æ–°æ•°æ®
        for _, row in df.iterrows():
            new_df_rows.append(row)
        
        self.logger.info(f"è¦†ç›–åŒæ­¥è®¡åˆ’: åˆ é™¤ {deleted_count} è¡Œï¼Œæ–°å¢ {len(df)} è¡Œ")
        
        # é‡å†™æ•´ä¸ªè¡¨æ ¼
        if new_df_rows:
            new_df = pd.DataFrame(new_df_rows)
            values = self.df_to_values(new_df)
            end_col = self.column_number_to_letter(len(new_df.columns))
            range_str = self.get_range_string(1, "A", len(values), end_col)
            
            # å…ˆæ¸…ç©ºç°æœ‰æ•°æ®ï¼Œç„¶åå†™å…¥æ–°æ•°æ®
            return self.api_client.write_sheet_data(self.config.spreadsheet_token, range_str, values)
        else:
            # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œæ¸…ç©ºè¡¨æ ¼
            return self.api_client.clear_sheet_data(self.config.spreadsheet_token, f"{self.config.sheet_id}!A:Z")
    
    def sync_clone(self, df: pd.DataFrame) -> bool:
        """å…‹éš†åŒæ­¥ï¼šæ¸…ç©ºå…¨éƒ¨ï¼Œç„¶åæ–°å¢å…¨éƒ¨"""
        self.logger.info("å¼€å§‹å…‹éš†åŒæ­¥...")
        
        # è½¬æ¢æ•°æ®æ ¼å¼
        values = self.df_to_values(df)
        end_col = self.column_number_to_letter(len(df.columns))
        range_str = self.get_range_string(1, "A", len(values), end_col)
        
        self.logger.info(f"å…‹éš†åŒæ­¥è®¡åˆ’: æ¸…ç©ºç°æœ‰æ•°æ®ï¼Œæ–°å¢ {len(df)} è¡Œ")
        
        # ç›´æ¥å†™å…¥æ•°æ®ï¼ˆä¼šè¦†ç›–ç°æœ‰æ•°æ®ï¼‰
        return self.api_client.write_sheet_data(self.config.spreadsheet_token, range_str, values)
    
    def sync(self, df: pd.DataFrame) -> bool:
        """æ‰§è¡ŒåŒæ­¥"""
        self.logger.info(f"å¼€å§‹æ‰§è¡Œ {self.config.sync_mode.value} åŒæ­¥æ¨¡å¼")
        self.logger.info(f"æ•°æ®æº: {len(df)} è¡Œ x {len(df.columns)} åˆ—")
        
        # é‡ç½®è½¬æ¢ç»Ÿè®¡
        self.conversion_stats = {
            'success': 0,
            'failed': 0,
            'warnings': []
        }
        
        # æ ¹æ®åŒæ­¥æ¨¡å¼æ‰§è¡Œå¯¹åº”æ“ä½œ
        sync_result = False
        if self.config.sync_mode == SyncMode.FULL:
            sync_result = self.sync_full(df)
        elif self.config.sync_mode == SyncMode.INCREMENTAL:
            sync_result = self.sync_incremental(df)
        elif self.config.sync_mode == SyncMode.OVERWRITE:
            sync_result = self.sync_overwrite(df)
        elif self.config.sync_mode == SyncMode.CLONE:
            sync_result = self.sync_clone(df)
        else:
            self.logger.error(f"ä¸æ”¯æŒçš„åŒæ­¥æ¨¡å¼: {self.config.sync_mode}")
            return False
        
        return sync_result


class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""
    
    @staticmethod
    def load_from_file(config_file: str) -> Optional[Dict[str, Any]]:
        """ä»YAMLæ–‡ä»¶åŠ è½½é…ç½®"""
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            print(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
            return None
        except yaml.YAMLError as e:
            print(f"YAMLé…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
            return None
    
    @staticmethod
    def save_to_file(config: Dict[str, Any], config_file: str):
        """ä¿å­˜é…ç½®åˆ°YAMLæ–‡ä»¶"""
        with open(config_file, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True, indent=2)
    
    @staticmethod
    def parse_args() -> argparse.Namespace:
        """è§£æå‘½ä»¤è¡Œå‚æ•°"""
        parser = argparse.ArgumentParser(description='XTF_Sheet - Excel To Feishu åŒæ­¥å·¥å…·ï¼ˆæ”¯æŒå¤šç»´è¡¨æ ¼å’Œç”µå­è¡¨æ ¼ï¼‰')
        
        # åŸºç¡€é…ç½®
        parser.add_argument('--config', '-c', type=str, default='config.yaml',
                          help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml)')
        parser.add_argument('--file-path', type=str, help='Excelæ–‡ä»¶è·¯å¾„')
        parser.add_argument('--app-id', type=str, help='é£ä¹¦åº”ç”¨ID')
        parser.add_argument('--app-secret', type=str, help='é£ä¹¦åº”ç”¨å¯†é’¥')
        
        # ç›®æ ‡å¹³å°é…ç½®
        parser.add_argument('--target-type', type=str, choices=['bitable', 'sheet'],
                          help='ç›®æ ‡ç±»å‹: bitable(å¤šç»´è¡¨æ ¼) æˆ– sheet(ç”µå­è¡¨æ ¼)')
        
        # å¤šç»´è¡¨æ ¼é…ç½®
        parser.add_argument('--app-token', type=str, help='å¤šç»´è¡¨æ ¼åº”ç”¨Token')
        parser.add_argument('--table-id', type=str, help='æ•°æ®è¡¨ID')
        parser.add_argument('--create-missing-fields', action='store_true', help='è‡ªåŠ¨åˆ›å»ºç¼ºå¤±å­—æ®µ')
        
        # ç”µå­è¡¨æ ¼é…ç½®
        parser.add_argument('--spreadsheet-token', type=str, help='ç”µå­è¡¨æ ¼Token')
        parser.add_argument('--sheet-id', type=str, help='å·¥ä½œè¡¨ID')
        parser.add_argument('--start-row', type=int, help='å¼€å§‹è¡Œå·')
        parser.add_argument('--start-column', type=str, help='å¼€å§‹åˆ—å·')
        
        # åŒæ­¥è®¾ç½®
        parser.add_argument('--sync-mode', type=str, 
                          choices=['full', 'incremental', 'overwrite', 'clone'],
                          help='åŒæ­¥æ¨¡å¼')
        parser.add_argument('--index-column', type=str, help='ç´¢å¼•åˆ—å')
        
        # æ€§èƒ½è®¾ç½®
        parser.add_argument('--batch-size', type=int, help='æ‰¹å¤„ç†å¤§å°')
        parser.add_argument('--rate-limit-delay', type=float, help='æ¥å£è°ƒç”¨é—´éš”ç§’æ•°')
        parser.add_argument('--max-retries', type=int, help='æœ€å¤§é‡è¯•æ¬¡æ•°')
        
        # æ—¥å¿—è®¾ç½®
        parser.add_argument('--log-level', type=str, 
                          choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                          help='æ—¥å¿—çº§åˆ«')
        
        return parser.parse_args()
    
    @classmethod
    def create_config(cls) -> SyncConfig:
        """åˆ›å»ºé…ç½®å¯¹è±¡"""
        args = cls.parse_args()
        
        # å…ˆè®¾ç½®é»˜è®¤å€¼
        config_data = {
            'sync_mode': 'full',
            'start_row': 1,
            'start_column': 'A',
            'batch_size': 1000,
            'rate_limit_delay': 0.1,
            'max_retries': 3,
            'log_level': 'INFO'
        }
        
        # å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½ï¼Œè¦†ç›–é»˜è®¤å€¼
        if Path(args.config).exists():
            file_config = cls.load_from_file(args.config)
            if file_config:
                config_data.update(file_config)
                print(f"âœ… å·²ä»é…ç½®æ–‡ä»¶åŠ è½½å‚æ•°: {args.config}")
        else:
            print(f"âš ï¸  é…ç½®æ–‡ä»¶ {args.config} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        
        # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–æ–‡ä»¶é…ç½®
        cli_overrides = []
        
        # åŸºç¡€å‚æ•°
        if args.file_path:
            config_data['file_path'] = args.file_path
            cli_overrides.append(f"file_path={args.file_path}")
        if args.app_id:
            config_data['app_id'] = args.app_id
            cli_overrides.append(f"app_id={args.app_id[:8]}...")
        if args.app_secret:
            config_data['app_secret'] = args.app_secret
            cli_overrides.append(f"app_secret=***")
        if args.spreadsheet_token:
            config_data['spreadsheet_token'] = args.spreadsheet_token
            cli_overrides.append(f"spreadsheet_token={args.spreadsheet_token[:8]}...")
        if args.sheet_id:
            config_data['sheet_id'] = args.sheet_id
            cli_overrides.append(f"sheet_id={args.sheet_id}")
        if args.index_column:
            config_data['index_column'] = args.index_column
            cli_overrides.append(f"index_column={args.index_column}")
        if args.start_row is not None:
            config_data['start_row'] = args.start_row
            cli_overrides.append(f"start_row={args.start_row}")
        if args.start_column:
            config_data['start_column'] = args.start_column
            cli_overrides.append(f"start_column={args.start_column}")
        
        # é«˜çº§å‚æ•°
        if args.sync_mode is not None:
            config_data['sync_mode'] = args.sync_mode
            cli_overrides.append(f"sync_mode={args.sync_mode}")
        if args.batch_size is not None:
            config_data['batch_size'] = args.batch_size
            cli_overrides.append(f"batch_size={args.batch_size}")
        if args.rate_limit_delay is not None:
            config_data['rate_limit_delay'] = args.rate_limit_delay
            cli_overrides.append(f"rate_limit_delay={args.rate_limit_delay}")
        if args.max_retries is not None:
            config_data['max_retries'] = args.max_retries
            cli_overrides.append(f"max_retries={args.max_retries}")
        if args.log_level is not None:
            config_data['log_level'] = args.log_level
            cli_overrides.append(f"log_level={args.log_level}")
        
        # æ˜¾ç¤ºå‘½ä»¤è¡Œè¦†ç›–çš„å‚æ•°
        if cli_overrides:
            print(f"ğŸ”§ å‘½ä»¤è¡Œå‚æ•°è¦†ç›–: {', '.join(cli_overrides)}")
        
        # éªŒè¯å¿…éœ€å‚æ•°
        required_fields = ['file_path', 'app_id', 'app_secret', 'spreadsheet_token', 'sheet_id']
        missing_fields = [f for f in required_fields if not config_data.get(f)]
        
        if missing_fields:
            print(f"\nâŒ é”™è¯¯: ç¼ºå°‘å¿…éœ€å‚æ•°: {', '.join(missing_fields)}")
            print("ğŸ’¡ è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼æä¾›è¿™äº›å‚æ•°:")
            print("   1. åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®")
            print("   2. é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®š")
            print("\nå‘½ä»¤è¡Œå‚æ•°ç¤ºä¾‹:")
            for field in missing_fields:
                field_name = field.replace('_', '-')
                print(f"   --{field_name} <å€¼>")
            sys.exit(1)
        
        return SyncConfig(**config_data)


def create_sample_config(config_file: str = "config.yaml"):
    """åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶"""
    sample_config = {
        "file_path": "data.xlsx",
        "app_id": "cli_your_app_id",
        "app_secret": "your_app_secret",
        "spreadsheet_token": "your_spreadsheet_token",
        "sheet_id": "your_sheet_id",
        "sync_mode": "full",
        "index_column": "ID",
        "start_row": 1,
        "start_column": "A",
        "batch_size": 1000,
        "rate_limit_delay": 0.1,
        "max_retries": 3,
        "log_level": "INFO"
    }
    
    if not Path(config_file).exists():
        ConfigManager.save_to_file(sample_config, config_file)
        print(f"å·²åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶: {config_file}")
        print("è¯·ç¼–è¾‘é…ç½®æ–‡ä»¶å¹¶å¡«å…¥æ­£ç¡®çš„å‚æ•°å€¼")
        return True
    else:
        print(f"é…ç½®æ–‡ä»¶ {config_file} å·²å­˜åœ¨")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("     XTF_Sheet ç”µå­è¡¨æ ¼åŒæ­¥å·¥å…·")
    print("     æ”¯æŒå››ç§åŒæ­¥æ¨¡å¼ï¼šå…¨é‡ã€å¢é‡ã€è¦†ç›–ã€å…‹éš†")
    print("=" * 70)

    # æ˜¾ç¤º Excel å¼•æ“ä¿¡æ¯
    print_engine_info()

    try:
        # å…ˆè§£æå‘½ä»¤è¡Œå‚æ•°ä»¥è·å–é…ç½®æ–‡ä»¶è·¯å¾„
        import argparse
        parser = argparse.ArgumentParser(add_help=False)
        parser.add_argument('--config', '-c', type=str, default='config.yaml')
        args, _ = parser.parse_known_args()
        config_file_path = args.config
        
        # å¦‚æœæŒ‡å®šçš„é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºç¤ºä¾‹é…ç½®
        if not Path(config_file_path).exists():
            print(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file_path}")
            if create_sample_config(config_file_path):
                print(f"è¯·ç¼–è¾‘ {config_file_path} æ–‡ä»¶å¹¶é‡æ–°è¿è¡Œç¨‹åº")
            return
        
        # åŠ è½½é…ç½®
        config = ConfigManager.create_config()
        
        # æ˜¾ç¤ºåŠ è½½çš„é…ç½®ä¿¡æ¯
        print(f"\nğŸ“‹ å·²åŠ è½½é…ç½®:")
        print(f"  é…ç½®æ–‡ä»¶: {config_file_path}")
        print(f"  Excelæ–‡ä»¶: {config.file_path}")
        print(f"  ç”µå­è¡¨æ ¼Token: {config.spreadsheet_token[:8]}...")
        print(f"  å·¥ä½œè¡¨ID: {config.sheet_id}")
        print(f"  åŒæ­¥æ¨¡å¼: {config.sync_mode.value}")
        print(f"  ç´¢å¼•åˆ—: {config.index_column or 'æœªæŒ‡å®š'}")
        print(f"  å¼€å§‹ä½ç½®: {config.start_column}{config.start_row}")
        print(f"  æ‰¹å¤„ç†å¤§å°: {config.batch_size}")
        print(f"  æ¥å£è°ƒç”¨é—´éš”: {config.rate_limit_delay}ç§’")
        print(f"  æœ€å¤§é‡è¯•æ¬¡æ•°: {config.max_retries}")
        print(f"  æ—¥å¿—çº§åˆ«: {config.log_level}")
        
        # éªŒè¯æ–‡ä»¶
        file_path = Path(config.file_path)
        if not file_path.exists():
            print(f"\nâŒ é”™è¯¯: Excelæ–‡ä»¶ä¸å­˜åœ¨ - {file_path}")
            print("è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„ file_path å‚æ•°")
            return
        
        # è¯»å–Excelæ–‡ä»¶
        print(f"\nğŸ“– æ­£åœ¨è¯»å–æ–‡ä»¶: {file_path}")
        try:
            df = smart_read_excel(file_path)
            print(f"âœ… æ–‡ä»¶è¯»å–æˆåŠŸï¼Œå…± {len(df)} è¡Œï¼Œ{len(df.columns)} åˆ—")
            print(f"ğŸ“Š åˆ—å: {', '.join(df.columns.tolist())}")
        except Exception as e:
            print(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            return
        
        # åˆ›å»ºåŒæ­¥å¼•æ“
        sync_engine = XTFSheetSyncEngine(config)
        
        # æ‰§è¡ŒåŒæ­¥
        print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œ {config.sync_mode.value} åŒæ­¥...")
        start_time = time.time()
        
        success = sync_engine.sync(df)
        
        end_time = time.time()
        duration = end_time - start_time
        
        if success:
            print(f"\nâœ… åŒæ­¥å®Œæˆï¼è€—æ—¶: {duration:.2f} ç§’")
            print(f"ğŸ“Š åŒæ­¥åˆ°ç”µå­è¡¨æ ¼: https://feishu.cn/sheets/{config.spreadsheet_token}")
        else:
            print(f"\nâŒ åŒæ­¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶")
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {str(e)}")
        logging.error(f"ç¨‹åºå¼‚å¸¸: {e}", exc_info=True)


if __name__ == "__main__":
    main()