#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€æ•°æ®è½¬æ¢æ¨¡å—
æä¾›å¤šç»´è¡¨æ ¼å’Œç”µå­è¡¨æ ¼çš„æ•°æ®è½¬æ¢åŠŸèƒ½
"""

import re
import pandas as pd
import hashlib
import logging
from typing import Dict, Any, List, Optional
import datetime as dt

from .config import TargetType


class DataConverter:
    """ç»Ÿä¸€æ•°æ®è½¬æ¢å™¨"""
    
    def __init__(self, target_type: TargetType):
        """
        åˆå§‹åŒ–æ•°æ®è½¬æ¢å™¨
        
        Args:
            target_type: ç›®æ ‡ç±»å‹ï¼ˆå¤šç»´è¡¨æ ¼æˆ–ç”µå­è¡¨æ ¼ï¼‰
        """
        self.target_type = target_type
        self.logger = logging.getLogger('XTF.converter')
        
        # ç±»å‹è½¬æ¢ç»Ÿè®¡
        self.conversion_stats = {
            'success': 0,
            'failed': 0,
            'warnings': []
        }
    
    def reset_stats(self):
        """é‡ç½®è½¬æ¢ç»Ÿè®¡"""
        self.conversion_stats = {
            'success': 0,
            'failed': 0,
            'warnings': []
        }
    
    def get_index_value_hash(self, row: pd.Series, index_column: Optional[str]) -> Optional[str]:
        """è®¡ç®—ç´¢å¼•å€¼çš„å“ˆå¸Œ"""
        if index_column and index_column in row:
            value = str(row[index_column])
            return hashlib.md5(value.encode('utf-8')).hexdigest()
        return None
    
    # ========== å¤šç»´è¡¨æ ¼è½¬æ¢æ–¹æ³• ==========
    
    def build_record_index(self, records: List[Dict], index_column: Optional[str]) -> Dict[str, Dict]:
        """æ„å»ºå¤šç»´è¡¨æ ¼è®°å½•ç´¢å¼•"""
        index = {}
        if not index_column:
            return index
        
        for record in records:
            fields = record.get('fields', {})
            if index_column in fields:
                raw_value = fields[index_column]
                
                # å¤„ç†å¯Œæ–‡æœ¬æ ¼å¼ï¼š[{'text': 'å†…å®¹', 'type': 'text'}] 
                if isinstance(raw_value, list) and len(raw_value) > 0:
                    if isinstance(raw_value[0], dict) and 'text' in raw_value[0]:
                        index_value = raw_value[0]['text']
                    else:
                        index_value = str(raw_value[0])
                elif isinstance(raw_value, dict) and 'text' in raw_value:
                    index_value = raw_value['text']
                else:
                    index_value = str(raw_value)
                
                index_hash = hashlib.md5(index_value.encode('utf-8')).hexdigest()
                index[index_hash] = record
        
        return index
    
    def _detect_excel_validation(self, df: pd.DataFrame, column_name: str) -> tuple:
        """
        æ£€æµ‹Excelåˆ—æ˜¯å¦åŒ…å«æ•°æ®éªŒè¯(ä¸‹æ‹‰åˆ—è¡¨)
        
        Returns:
            (æ˜¯å¦æœ‰éªŒè¯, éªŒè¯ç±»å‹æè¿°)
        """
        try:
            # æ–¹æ³•1: æ£€æŸ¥pandasæ˜¯å¦ä¿ç•™äº†ExceléªŒè¯ä¿¡æ¯
            if hasattr(df, '_excel_validation_info'):
                validation_info = df._excel_validation_info.get(column_name)
                if validation_info:
                    return True, validation_info.get('type', 'unknown')
            
            # æ–¹æ³•2: åŸºäºæ•°æ®æ¨¡å¼æ¨æ–­
            column_data = df[column_name].dropna()
            if len(column_data) == 0:
                return False, "empty"
            
            unique_values = set(str(v) for v in column_data)
            unique_count = len(unique_values)
            total_count = len(column_data)
            
            # ä¸‹æ‹‰åˆ—è¡¨ç‰¹å¾æ£€æµ‹
            validation_indicators = []
            
            # ç‰¹å¾1: æå°‘çš„å”¯ä¸€å€¼ä¸”é«˜é‡å¤ç‡
            if unique_count <= 8 and unique_count / total_count <= 0.3:
                validation_indicators.append("low_unique_high_repeat")
            
            # ç‰¹å¾2: å€¼éƒ½æ˜¯ç®€çŸ­çš„æ ‡è¯†ç¬¦
            if all(len(str(v)) <= 20 for v in unique_values):
                validation_indicators.append("short_identifiers")
            
            # ç‰¹å¾3: æ²¡æœ‰ç‰¹æ®Šå­—ç¬¦å’Œå¤æ‚æ ¼å¼
            if all(not re.search(r'[^\w\s\-_()(ï¼ˆï¼‰)]', str(v)) for v in unique_values):
                validation_indicators.append("simple_format")
            
            # ç‰¹å¾4: å€¼çœ‹èµ·æ¥åƒæšä¸¾é€‰é¡¹
            enum_patterns = [
                r'^(çŠ¶æ€|çº§åˆ«|ç±»å‹|åˆ†ç±»)[\w\s]*$',  # çŠ¶æ€ç±»
                r'^(é«˜|ä¸­|ä½)$',                   # ç­‰çº§ç±»
                r'^(æ˜¯|å¦|true|false)$',          # å¸ƒå°”ç±»
                r'^(å®Œæˆ|è¿›è¡Œä¸­|å¾…å¼€å§‹|å·²å–æ¶ˆ)$',    # æµç¨‹çŠ¶æ€
                r'^[A-Z]{1,3}$',                  # ç®€çŸ­ä»£ç 
            ]
            
            enum_matches = sum(
                1 for v in unique_values 
                if any(re.match(pattern, str(v), re.IGNORECASE) for pattern in enum_patterns)
            )
            
            if enum_matches >= unique_count * 0.6:  # 60%ä»¥ä¸ŠåŒ¹é…æšä¸¾æ¨¡å¼
                validation_indicators.append("enum_pattern")
            
            # åˆ¤æ–­æ˜¯å¦å¯èƒ½æ˜¯ä¸‹æ‹‰åˆ—è¡¨
            if len(validation_indicators) >= 3:
                return True, f"suspected_dropdown({','.join(validation_indicators)})"
            elif len(validation_indicators) >= 2 and unique_count <= 5:
                return True, f"possible_dropdown({','.join(validation_indicators)})"
            
            return False, "no_validation_detected"
            
        except Exception as e:
            return False, f"detection_error: {e}"
    
    def analyze_excel_column_data(self, df: pd.DataFrame, column_name: str) -> Dict[str, Any]:
        """åˆ†æExcelåˆ—çš„æ•°æ®ç‰¹å¾ï¼Œç”¨äºæ¨æ–­åˆé€‚çš„é£ä¹¦å­—æ®µç±»å‹"""
        column_data = df[column_name].dropna()
        total_count = len(column_data)
        
        if total_count == 0:
            return {
                'primary_type': 'string',
                'suggested_feishu_type': 1,  # æ–‡æœ¬
                'confidence': 0.5,
                'analysis': 'åˆ—ä¸ºç©ºï¼Œé»˜è®¤æ–‡æœ¬ç±»å‹'
            }
        
        # æ•°æ®ç±»å‹ç»Ÿè®¡
        type_stats = {
            'string': 0,
            'number': 0,
            'datetime': 0,
            'boolean': 0
        }
        
        unique_values = set()
        for value in column_data:
            unique_values.add(str(value))
            
            # æ•°å€¼æ£€æµ‹
            if isinstance(value, (int, float)):
                type_stats['number'] += 1
            elif isinstance(value, str):
                str_val = str(value).strip()
                # å¸ƒå°”å€¼æ£€æµ‹ - æ’é™¤çº¯æ•°å­—å­—ç¬¦ä¸²
                if str_val.lower() in ['true', 'false', 'æ˜¯', 'å¦', 'yes', 'no', 'on', 'off']:
                    type_stats['boolean'] += 1
                # æ•°å­—æ£€æµ‹
                elif self._is_number_string(str_val):
                    type_stats['number'] += 1
                # æ—¶é—´æˆ³æ£€æµ‹
                elif self._is_timestamp_string(str_val):
                    type_stats['datetime'] += 1
                # æ—¥æœŸæ ¼å¼æ£€æµ‹
                elif self._is_date_string(str_val):
                    type_stats['datetime'] += 1
                else:
                    type_stats['string'] += 1
            else:
                type_stats['string'] += 1
        
        # è®¡ç®—ä¸»è¦ç±»å‹
        primary_type = max(type_stats.keys(), key=lambda k: type_stats[k])
        confidence = type_stats[primary_type] / total_count
        
        # æ¨æ–­é£ä¹¦å­—æ®µç±»å‹ (ä¼ ç»Ÿæ–¹æ³•ï¼Œä¿æŒå…¼å®¹æ€§)
        suggested_type = self._suggest_feishu_field_type(
            primary_type, unique_values, total_count, confidence
        )
        
        return {
            'primary_type': primary_type,
            'suggested_feishu_type': suggested_type,
            'confidence': confidence,
            'unique_count': len(unique_values),
            'total_count': total_count,
            'type_distribution': type_stats,
            'analysis': f'{primary_type}ç±»å‹å æ¯”{confidence:.1%}'
        }
    
    def _is_number_string(self, s: str) -> bool:
        """æ£€æµ‹å­—ç¬¦ä¸²æ˜¯å¦ä¸ºæ•°å­—"""
        try:
            float(s.replace(',', ''))  # æ”¯æŒåƒåˆ†ä½åˆ†éš”ç¬¦
            return True
        except ValueError:
            return False
    
    def _is_timestamp_string(self, s: str) -> bool:
        """æ£€æµ‹å­—ç¬¦ä¸²æ˜¯å¦ä¸ºæ—¶é—´æˆ³"""
        is_timestamp, _ = self._is_timestamp_enhanced(s)
        return is_timestamp
    
    def _is_timestamp_enhanced(self, s: str) -> tuple:
        """å¢å¼ºçš„æ—¶é—´æˆ³æ£€æµ‹"""
        from datetime import datetime
        
        if not s.isdigit():
            return False, 0.0
        
        try:
            timestamp = int(s)
            current_year = datetime.now().year
            
            # ç§’çº§æ—¶é—´æˆ³: 1970-2050å¹´
            if 946684800 <= timestamp <= 2524608000:  # 2000-2050
                confidence = 0.9 if 1640995200 <= timestamp <= 1893456000 else 0.7  # 2022-2030æ›´é«˜ç½®ä¿¡åº¦
                return True, confidence
                
            # æ¯«ç§’çº§æ—¶é—´æˆ³: 2000-2050å¹´  
            elif 946656000000 <= timestamp <= 2524579200000:
                confidence = 0.85
                return True, confidence
                
            # å¾®ç§’çº§(Excelæœ‰æ—¶å¯¼å‡º): è¿‡äºé•¿çš„æ•°å­—é™ä½ç½®ä¿¡åº¦
            elif len(s) >= 13:
                return True, 0.3
                
        except ValueError:
            pass
            
        return False, 0.0
    
    def _is_date_string(self, s: str) -> bool:
        """æ£€æµ‹å­—ç¬¦ä¸²æ˜¯å¦ä¸ºæ—¥æœŸæ ¼å¼"""
        is_date, _, _ = self._is_date_string_enhanced(s)
        return is_date
    
    def _is_date_string_enhanced(self, s: str) -> tuple:
        """
        å¢å¼ºçš„æ—¥æœŸæ£€æµ‹ï¼Œè¿”å›(æ˜¯å¦æ—¥æœŸ, ç½®ä¿¡åº¦, æ£€æµ‹åˆ°çš„æ ¼å¼)
        """
        from datetime import datetime
        
        s = s.strip()
        if not s:
            return False, 0.0, ""
        
        # æ‰©å±•çš„æ—¥æœŸæ ¼å¼æ¨¡å¼ (æŒ‰å¸¸è§ç¨‹åº¦æ’åº)
        date_patterns = [
            # æ ‡å‡†ISOæ ¼å¼ (æœ€é«˜ç½®ä¿¡åº¦)
            (r'^\d{4}-\d{2}-\d{2}$', '%Y-%m-%d', 0.95),                    # 2024-01-01
            (r'^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$', '%Y-%m-%d %H:%M:%S', 0.95), # 2024-01-01 12:30:45
            (r'^\d{4}-\d{2}-\d{2} \d{2}:\d{2}$', '%Y-%m-%d %H:%M', 0.9),   # 2024-01-01 12:30
            
            # å¸¸è§åˆ†éš”ç¬¦æ ¼å¼
            (r'^\d{4}/\d{1,2}/\d{1,2}$', '%Y/%m/%d', 0.85),               # 2024/1/1
            (r'^\d{1,2}/\d{1,2}/\d{4}$', '%m/%d/%Y', 0.7),                # 1/1/2024 (å­˜åœ¨æ­§ä¹‰)
            (r'^\d{1,2}-\d{1,2}-\d{4}$', '%m-%d-%Y', 0.7),                # 1-1-2024
            
            # ä¸­æ–‡æ ¼å¼
            (r'^\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥$', '%Yå¹´%mæœˆ%dæ—¥', 0.9),         # 2024å¹´1æœˆ1æ—¥
            (r'^\d{1,2}æœˆ\d{1,2}æ—¥$', '%mæœˆ%dæ—¥', 0.8),                    # 1æœˆ1æ—¥
            (r'^\d{4}\.\d{1,2}\.\d{1,2}$', '%Y.%m.%d', 0.8),              # 2024.1.1
            
            # Excelå¸¸è§æ ¼å¼
            (r'^\d{4}-\d{1,2}-\d{1,2}T\d{2}:\d{2}:\d{2}', '%Y-%m-%dT%H:%M:%S', 0.95), # ISOæ—¶é—´
        ]
        
        for pattern, fmt, base_confidence in date_patterns:
            if re.match(pattern, s):
                try:
                    # å°è¯•è§£æéªŒè¯æ—¥æœŸæœ‰æ•ˆæ€§
                    if 'T' in fmt:  # ISOæ ¼å¼ç‰¹æ®Šå¤„ç†
                        parsed_date = datetime.fromisoformat(s.replace('T', ' ')[:19])
                    else:
                        parsed_date = datetime.strptime(s, fmt)
                    
                    # åˆç†æ€§æ£€æŸ¥: 1900-2100å¹´
                    if 1900 <= parsed_date.year <= 2100:
                        # æ ¹æ®å®Œæ•´æ€§è°ƒæ•´ç½®ä¿¡åº¦
                        if parsed_date.hour == 0 and parsed_date.minute == 0:
                            confidence = base_confidence * 0.95  # çº¯æ—¥æœŸç•¥é™ç½®ä¿¡åº¦
                        else:
                            confidence = base_confidence  # åŒ…å«æ—¶é—´ä¿¡æ¯é«˜ç½®ä¿¡åº¦
                        
                        return True, confidence, fmt
                        
                except ValueError:
                    continue  # æ ¼å¼åŒ¹é…ä½†è§£æå¤±è´¥ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
        
        return False, 0.0, ""
    
    def _suggest_feishu_field_type(self, primary_type: str, unique_values: set, 
                                  total_count: int, confidence: float) -> int:
        """æ ¹æ®æ•°æ®ç‰¹å¾æ¨èé£ä¹¦å­—æ®µç±»å‹ (ä¿ç•™å…¼å®¹æ–¹æ³•ï¼Œå»ºè®®ä½¿ç”¨analyze_excel_column_data_enhanced)"""
        unique_count = len(unique_values)
        
        if primary_type == 'number':
            return 2  # æ•°å­—å­—æ®µ
        elif primary_type == 'datetime':
            return 5  # æ—¥æœŸå­—æ®µ
        elif primary_type == 'boolean':
            return 7  # å¤é€‰æ¡†å­—æ®µ
        elif primary_type == 'string':
            # å­—ç¬¦ä¸²ç±»å‹çš„ç»†åˆ†åˆ¤æ–­
            if unique_count <= 20 and unique_count / total_count <= 0.5:
                # å”¯ä¸€å€¼è¾ƒå°‘ä¸”é‡å¤ç‡é«˜ï¼Œæ¨èå•é€‰
                return 3  # å•é€‰å­—æ®µ
            elif any(',' in str(v) or ';' in str(v) or '|' in str(v) for v in unique_values):
                # åŒ…å«åˆ†éš”ç¬¦ï¼Œå¯èƒ½æ˜¯å¤šé€‰
                return 4  # å¤šé€‰å­—æ®µ
            else:
                return 1  # æ–‡æœ¬å­—æ®µ
        
        return 1  # é»˜è®¤æ–‡æœ¬å­—æ®µ
    
    def _suggest_feishu_field_type_raw(self) -> tuple:
        """
        åŸå€¼ç­–ç•¥ - æ‰€æœ‰å­—æ®µéƒ½ä½¿ç”¨æ–‡æœ¬ç±»å‹ï¼Œä¿æŒåŸå§‹æ•°æ®
        
        Returns:
            (å­—æ®µç±»å‹, æ¨èç†ç”±)
        """
        return 1, "rawç­–ç•¥ï¼Œæ‰€æœ‰å­—æ®µä½¿ç”¨æ–‡æœ¬ç±»å‹ä¿æŒåŸå€¼"
    
    def _suggest_feishu_field_type_base(self, primary_type: str, unique_values: set, 
                                       total_count: int, confidence: float) -> tuple:
        """
        åŸºç¡€ç­–ç•¥ - ä»…åˆ›å»ºæ–‡æœ¬/æ•°å­—/æ—¥æœŸä¸‰ç§åŸºç¡€ç±»å‹
        
        Returns:
            (å­—æ®µç±»å‹, æ¨èç†ç”±)
        """
        # 1. æ•°å­—ç±»å‹
        if primary_type == 'number' and confidence >= 0.8:
            return 2, f"æ•°å­—ç±»å‹ï¼Œç½®ä¿¡åº¦{confidence:.1%}"
        
        # 2. æ—¥æœŸç±»å‹ - éœ€è¦é«˜ç½®ä¿¡åº¦
        if primary_type == 'datetime' and confidence >= 0.85:
            return 5, f"æ—¥æœŸç±»å‹ï¼Œç½®ä¿¡åº¦{confidence:.1%}"
        
        # 3. æ‰€æœ‰å…¶ä»–æƒ…å†µéƒ½ä½¿ç”¨æ–‡æœ¬ç±»å‹
        if primary_type == 'datetime':
            return 1, f"æ—¥æœŸæ ¼å¼ç½®ä¿¡åº¦ä¸å¤Ÿ({confidence:.1%})ï¼Œä½¿ç”¨æ–‡æœ¬ç±»å‹"
        elif primary_type == 'number':
            return 1, f"æ•°å­—æ ¼å¼ç½®ä¿¡åº¦ä¸å¤Ÿ({confidence:.1%})ï¼Œä½¿ç”¨æ–‡æœ¬ç±»å‹"
        else:
            return 1, "åŸºç¡€ç­–ç•¥ï¼Œä½¿ç”¨æ–‡æœ¬ç±»å‹"
    
    def _suggest_feishu_field_type_auto(self, primary_type: str, unique_values: set, 
                                       total_count: int, confidence: float,
                                       has_excel_validation: bool = False) -> tuple:
        """
        è‡ªåŠ¨ç­–ç•¥ - åœ¨åŸºç¡€ç±»å‹ä¸Šå¢åŠ Excelç±»å‹æ£€æµ‹ï¼ˆå•é€‰å¤šé€‰ç­‰ï¼‰
        
        Args:
            has_excel_validation: æ˜¯å¦æ£€æµ‹åˆ°Excelæ•°æ®éªŒè¯(ä¸‹æ‹‰åˆ—è¡¨ç­‰)
        
        Returns:
            (å­—æ®µç±»å‹, æ¨èç†ç”±)
        """
        unique_count = len(unique_values)
        
        # 1. åŸºç¡€ç±»å‹ï¼šæ•°å­—
        if primary_type == 'number' and confidence >= 0.8:
            return 2, f"æ•°å­—ç±»å‹ï¼Œç½®ä¿¡åº¦{confidence:.1%}"
        
        # 2. åŸºç¡€ç±»å‹ï¼šæ—¥æœŸ
        if primary_type == 'datetime' and confidence >= 0.85:
            return 5, f"æ—¥æœŸç±»å‹ï¼Œç½®ä¿¡åº¦{confidence:.1%}"
        
        # 3. Excelç±»å‹æ£€æµ‹ï¼šä»…åœ¨æ£€æµ‹åˆ°ExceléªŒè¯æ—¶æ¨è
        if primary_type == 'string' and has_excel_validation:
            if unique_count <= 15 and unique_count / total_count <= 0.4:
                return 3, f"Excelä¸‹æ‹‰åˆ—è¡¨ï¼Œå”¯ä¸€å€¼{unique_count}ä¸ªï¼Œæ¨èå•é€‰"
            elif any(',' in str(v) or ';' in str(v) or '|' in str(v) for v in unique_values):
                return 4, f"Excelä¸‹æ‹‰åˆ—è¡¨åŒ…å«åˆ†éš”ç¬¦ï¼Œæ¨èå¤šé€‰"
        
        # 4. æ‰€æœ‰å…¶ä»–æƒ…å†µä½¿ç”¨æ–‡æœ¬ç±»å‹
        if primary_type == 'datetime':
            return 1, f"æ—¥æœŸæ ¼å¼ç½®ä¿¡åº¦ä¸å¤Ÿ({confidence:.1%})ï¼Œä½¿ç”¨æ–‡æœ¬ç±»å‹"
        elif primary_type == 'number':
            return 1, f"æ•°å­—æ ¼å¼ç½®ä¿¡åº¦ä¸å¤Ÿ({confidence:.1%})ï¼Œä½¿ç”¨æ–‡æœ¬ç±»å‹"
        else:
            return 1, "æœªæ£€æµ‹åˆ°ExceléªŒè¯ï¼Œä½¿ç”¨æ–‡æœ¬ç±»å‹"
    
    def _suggest_feishu_field_type_intelligence(self, primary_type: str, unique_values: set, 
                                               total_count: int, confidence: float,
                                               config) -> tuple:
        """
        æ™ºèƒ½ç­–ç•¥ - åŸºäºç½®ä¿¡åº¦ç®—æ³•ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é˜ˆå€¼
        
        Returns:
            (å­—æ®µç±»å‹, æ¨èç†ç”±)
        """
        unique_count = len(unique_values)
        
        # 1. æ•°å­—ç±»å‹
        if primary_type == 'number' and confidence >= 0.8:
            return 2, f"æ•°å­—ç±»å‹ï¼Œç½®ä¿¡åº¦{confidence:.1%}"
        
        # 2. æ—¥æœŸç±»å‹
        if primary_type == 'datetime' and confidence >= getattr(config, 'intelligence_date_confidence', 0.85):
            return 5, f"æ—¥æœŸç±»å‹ï¼Œç½®ä¿¡åº¦{confidence:.1%}"
        
        # 3. å¸ƒå°”ç±»å‹
        if (primary_type == 'boolean' and 
            confidence >= getattr(config, 'intelligence_boolean_confidence', 0.95) and 
            unique_count <= 3):
            return 7, f"å¸ƒå°”ç±»å‹ï¼Œç½®ä¿¡åº¦{confidence:.1%}"
        
        # 4. å­—ç¬¦ä¸²ç±»å‹çš„æ™ºèƒ½åˆ¤æ–­
        if primary_type == 'string':
            choice_threshold = getattr(config, 'intelligence_choice_confidence', 0.9)
            # å•é€‰æ£€æµ‹
            if (unique_count <= 20 and 
                unique_count / total_count <= 0.5 and
                confidence >= choice_threshold):
                return 3, f"æ™ºèƒ½åˆ¤æ–­ä¸ºå•é€‰ï¼ˆ{unique_count}ä¸ªé€‰é¡¹ï¼Œç½®ä¿¡åº¦{confidence:.1%}ï¼‰"
            
            # å¤šé€‰æ£€æµ‹
            elif (any(',' in str(v) or ';' in str(v) or '|' in str(v) for v in unique_values) and
                  confidence >= choice_threshold):
                return 4, f"æ™ºèƒ½æ£€æµ‹åˆ°å¤šé€‰æ¨¡å¼ï¼Œç½®ä¿¡åº¦{confidence:.1%}"
        
        # 5. å…œåº•ç­–ç•¥
        if primary_type == 'datetime':
            date_threshold = getattr(config, 'intelligence_date_confidence', 0.85)
            return 1, f"æ—¥æœŸç½®ä¿¡åº¦ä¸å¤Ÿ({confidence:.1%}<{date_threshold:.1%})ï¼Œä½¿ç”¨æ–‡æœ¬ç±»å‹"
        elif primary_type == 'boolean':
            bool_threshold = getattr(config, 'intelligence_boolean_confidence', 0.95)
            return 1, f"å¸ƒå°”ç½®ä¿¡åº¦ä¸å¤Ÿ({confidence:.1%}<{bool_threshold:.1%})ï¼Œä½¿ç”¨æ–‡æœ¬ç±»å‹"
        elif primary_type == 'string':
            choice_threshold = getattr(config, 'intelligence_choice_confidence', 0.9)
            return 1, f"é€‰æ‹©ç±»å‹ç½®ä¿¡åº¦ä¸å¤Ÿ({confidence:.1%}<{choice_threshold:.1%})ï¼Œä½¿ç”¨æ–‡æœ¬ç±»å‹"
        else:
            return 1, "æ™ºèƒ½åˆ†ææ— æ³•ç¡®å®šç±»å‹ï¼Œä½¿ç”¨æ–‡æœ¬ç±»å‹"
    
    def get_field_type_name(self, field_type: int) -> str:
        """è·å–å­—æ®µç±»å‹çš„ä¸­æ–‡åç§°"""
        type_names = {
            1: "æ–‡æœ¬", 2: "æ•°å­—", 3: "å•é€‰", 4: "å¤šé€‰", 5: "æ—¥æœŸ", 
            7: "å¤é€‰æ¡†", 11: "äººå‘˜", 13: "ç”µè¯", 15: "è¶…é“¾æ¥", 
            17: "é™„ä»¶", 18: "å•å‘å…³è”", 21: "åŒå‘å…³è”", 22: "åœ°ç†ä½ç½®", 23: "ç¾¤ç»„"
        }
        return type_names.get(field_type, f"æœªçŸ¥ç±»å‹({field_type})")
    
    def analyze_excel_column_data_enhanced(self, df: pd.DataFrame, column_name: str, 
                                          strategy: str = 'base', config = None) -> Dict[str, Any]:
        """
        å¢å¼ºçš„Excelåˆ—æ•°æ®åˆ†æ - æ”¯æŒä¸‰ç§å­—æ®µç±»å‹ç­–ç•¥
        
        Args:
            df: Excelæ•°æ®
            column_name: åˆ—å
            strategy: å­—æ®µç±»å‹ç­–ç•¥ ('base' | 'auto' | 'intelligence')
            config: é…ç½®å¯¹è±¡ (intelligenceç­–ç•¥å¿…éœ€)
            
        Returns:
            åŒ…å«æ¨èå­—æ®µç±»å‹å’Œç†ç”±çš„åˆ†æç»“æœ
        """
        from .config import FieldTypeStrategy
        
        # 1. æ£€æµ‹ExceléªŒè¯ä¿¡æ¯ï¼ˆä»…autoç­–ç•¥éœ€è¦ï¼‰
        has_validation = False
        validation_type = "not_checked"
        if strategy == FieldTypeStrategy.AUTO.value:
            has_validation, validation_type = self._detect_excel_validation(df, column_name)
        
        # 2. åŸºç¡€æ•°æ®åˆ†æ
        analysis = self.analyze_excel_column_data(df, column_name)  # å¤ç”¨ç°æœ‰é€»è¾‘
        
        # 3. å¢å¼ºçš„æ—¥æœŸæ£€æµ‹
        if analysis['primary_type'] == 'string':
            column_data = df[column_name].dropna()
            date_confidence_sum = 0
            date_count = 0
            
            for value in column_data:
                is_date, confidence_val, format_type = self._is_date_string_enhanced(str(value))
                if is_date:
                    date_confidence_sum += confidence_val
                    date_count += 1
            
            if date_count > 0:
                avg_date_confidence = date_confidence_sum / len(column_data)
                if avg_date_confidence >= 0.6:  # 60%ä»¥ä¸Šæ˜¯é«˜è´¨é‡æ—¥æœŸ
                    analysis['primary_type'] = 'datetime'
                    analysis['confidence'] = avg_date_confidence
        
        # 4. åº”ç”¨å­—æ®µç±»å‹ç­–ç•¥
        unique_values = set(str(v) for v in df[column_name].dropna())
        
        if strategy == FieldTypeStrategy.RAW.value:
            suggested_type, reason = self._suggest_feishu_field_type_raw()
        elif strategy == FieldTypeStrategy.BASE.value:
            suggested_type, reason = self._suggest_feishu_field_type_base(
                analysis['primary_type'], unique_values, analysis['total_count'], analysis['confidence']
            )
        elif strategy == FieldTypeStrategy.AUTO.value:
            suggested_type, reason = self._suggest_feishu_field_type_auto(
                analysis['primary_type'], unique_values, analysis['total_count'], 
                analysis['confidence'], has_validation
            )
        elif strategy == FieldTypeStrategy.INTELLIGENCE.value:
            if config is None:
                raise ValueError("Intelligenceç­–ç•¥éœ€è¦é…ç½®å¯¹è±¡")
            suggested_type, reason = self._suggest_feishu_field_type_intelligence(
                analysis['primary_type'], unique_values, analysis['total_count'], 
                analysis['confidence'], config
            )
        else:
            # å…œåº•ä½¿ç”¨åŸºç¡€ç­–ç•¥
            suggested_type, reason = self._suggest_feishu_field_type_base(
                analysis['primary_type'], unique_values, analysis['total_count'], analysis['confidence']
            )
        
        # 5. æ›´æ–°åˆ†æç»“æœ
        analysis.update({
            'suggested_feishu_type': suggested_type,
            'recommendation_reason': reason,
            'has_excel_validation': has_validation,
            'validation_type': validation_type,
            'strategy_used': strategy
        })
        
        return analysis
    
    def convert_field_value_safe(self, field_name: str, value, field_types: Optional[Dict[str, int]] = None):
        """å®‰å…¨çš„å­—æ®µå€¼è½¬æ¢"""
        if pd.isnull(value):
            return None
        
        # å¤šç»´è¡¨æ ¼æ¨¡å¼ä½¿ç”¨å¤æ‚è½¬æ¢
        if self.target_type == TargetType.BITABLE:
            # å¦‚æœæ²¡æœ‰å­—æ®µç±»å‹ä¿¡æ¯ï¼Œä½¿ç”¨æ™ºèƒ½è½¬æ¢
            if field_types is None or field_name not in field_types:
                return self.smart_convert_value(value)
            
            field_type = field_types[field_name]
            
            # å¼ºåˆ¶è½¬æ¢ä¸ºç›®æ ‡ç±»å‹ï¼ŒæŒ‰é£ä¹¦å­—æ®µç±»å‹è¿›è¡Œè½¬æ¢
            try:
                converted_value = self._force_convert_to_feishu_type(value, field_name, field_type)
                if converted_value is not None:
                    self.conversion_stats['success'] += 1
                    return converted_value
                else:
                    self.conversion_stats['failed'] += 1
                    return None
            except Exception as e:
                self.logger.warning(f"å­—æ®µ '{field_name}' å¼ºåˆ¶è½¬æ¢å¤±è´¥: {e}, åŸå§‹å€¼: '{value}'")
                self.conversion_stats['failed'] += 1
                return None
        else:
            # ç”µå­è¡¨æ ¼æ¨¡å¼ä½¿ç”¨ç®€å•è½¬æ¢
            return self.simple_convert_value(value)
    
    def _force_convert_to_feishu_type(self, value, field_name: str, field_type: int):
        """å¼ºåˆ¶è½¬æ¢å€¼ä¸ºæŒ‡å®šçš„é£ä¹¦å­—æ®µç±»å‹"""
        if field_type == 1:  # æ–‡æœ¬å­—æ®µ - æ‰€æœ‰å€¼éƒ½å¯ä»¥è½¬æ¢ä¸ºæ–‡æœ¬
            return str(value)
        elif field_type == 2:  # æ•°å­—å­—æ®µ - å¼ºåˆ¶è½¬æ¢ä¸ºæ•°å­—
            return self._force_to_number(value, field_name)
        elif field_type == 3:  # å•é€‰å­—æ®µ - è½¬æ¢ä¸ºå•ä¸ªå­—ç¬¦ä¸²
            return self._force_to_single_choice(value, field_name)
        elif field_type == 4:  # å¤šé€‰å­—æ®µ - è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ•°ç»„
            return self._force_to_multi_choice(value, field_name)
        elif field_type == 5:  # æ—¥æœŸå­—æ®µ - å¼ºåˆ¶è½¬æ¢ä¸ºæ—¶é—´æˆ³
            return self._force_to_timestamp(value, field_name)
        elif field_type == 7:  # å¤é€‰æ¡†å­—æ®µ - å¼ºåˆ¶è½¬æ¢ä¸ºå¸ƒå°”å€¼
            return self._force_to_boolean(value, field_name)
        elif field_type == 11:  # äººå‘˜å­—æ®µ
            return self.convert_to_user_field(value)
        elif field_type == 13:  # ç”µè¯å·ç å­—æ®µ
            return str(value)
        elif field_type == 15:  # è¶…é“¾æ¥å­—æ®µ
            return self.convert_to_url_field(value)
        elif field_type == 17:  # é™„ä»¶å­—æ®µ
            return self.convert_to_attachment_field(value)
        elif field_type in [18, 21]:  # å…³è”å­—æ®µ
            return self.convert_to_link_field(value)
        elif field_type == 22:  # åœ°ç†ä½ç½®å­—æ®µ
            return str(value)
        elif field_type == 23:  # ç¾¤ç»„å­—æ®µ
            return self.convert_to_user_field(value)
        elif field_type in [19, 20, 1001, 1002, 1003, 1004, 1005]:  # åªè¯»å­—æ®µ
            self.logger.debug(f"å­—æ®µ '{field_name}' æ˜¯åªè¯»å­—æ®µï¼Œè·³è¿‡è®¾ç½®")
            return None
        else:
            # æœªçŸ¥ç±»å‹ï¼Œé»˜è®¤è½¬ä¸ºå­—ç¬¦ä¸²
            return str(value)
    
    def _force_to_number(self, value, field_name: str):
        """å¼ºåˆ¶è½¬æ¢ä¸ºæ•°å­—"""
        if isinstance(value, (int, float)):
            return value
        
        if isinstance(value, str):
            str_val = value.strip()
            
            # å¤„ç†ç©ºå­—ç¬¦ä¸²
            if not str_val:
                return None
                
            # å¤„ç†å¸¸è§çš„éæ•°å­—è¡¨ç¤º
            non_numeric_map = {
                'null': None, 'n/a': None, 'na': None, 'æ— ': None, 'ç©º': None,
                'å¾…å®š': None, 'tbd': None, 'pending': None, 'æœªçŸ¥': None,
            }
            if str_val.lower() in non_numeric_map:
                return non_numeric_map[str_val.lower()]
            
            # æ¸…ç†æ•°å­—å­—ç¬¦ä¸²
            cleaned = str_val.replace(',', '').replace('ï¿¥', '').replace('$', '').replace('%', '')
            
            try:
                # å°è¯•è½¬æ¢ä¸ºæ•°å­—
                if '.' in cleaned:
                    return float(cleaned)
                return int(cleaned)
            except ValueError:
                # å¦‚æœåŒ…å«æ–‡å­—ï¼Œå°è¯•æå–æ•°å­—éƒ¨åˆ†
                numbers = re.findall(r'-?\d+\.?\d*', cleaned)
                if numbers:
                    try:
                        num = float(numbers[0]) if '.' in numbers[0] else int(numbers[0])
                        self.logger.warning(f"å­—æ®µ '{field_name}': ä» '{value}' ä¸­æå–æ•°å­— {num}")
                        return num
                    except ValueError:
                        pass
                
                # å®Œå…¨æ— æ³•è½¬æ¢æ—¶ï¼Œè®°å½•è­¦å‘Šå¹¶è¿”å›None
                self.logger.warning(f"å­—æ®µ '{field_name}': æ— æ³•å°† '{value}' è½¬æ¢ä¸ºæ•°å­—ï¼Œå°†å¿½ç•¥æ­¤å€¼")
                return None
        
        # å…¶ä»–ç±»å‹å°è¯•ç›´æ¥è½¬æ¢
        try:
            return float(value)
        except (ValueError, TypeError):
            self.logger.warning(f"å­—æ®µ '{field_name}': æ— æ³•å°† {type(value).__name__} '{value}' è½¬æ¢ä¸ºæ•°å­—")
            return None
    
    def _force_to_single_choice(self, value, field_name: str):
        """å¼ºåˆ¶è½¬æ¢ä¸ºå•é€‰å€¼"""
        if isinstance(value, str):
            # å¦‚æœåŒ…å«åˆ†éš”ç¬¦ï¼Œå–ç¬¬ä¸€ä¸ªå€¼
            for separator in [',', ';', '|', '\n']:
                if separator in value:
                    first_value = value.split(separator)[0].strip()
                    if first_value:
                        self.logger.info(f"å­—æ®µ '{field_name}': å¤šå€¼è½¬å•é€‰ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªå€¼: '{first_value}'")
                        return first_value
            return value.strip()
        
        return str(value)
    
    def _force_to_multi_choice(self, value, field_name: str):
        """å¼ºåˆ¶è½¬æ¢ä¸ºå¤šé€‰å€¼æ•°ç»„"""
        if isinstance(value, str):
            # å°è¯•æŒ‰åˆ†éš”ç¬¦æ‹†åˆ†
            for separator in [',', ';', '|', '\n']:
                if separator in value:
                    return [v.strip() for v in value.split(separator) if v.strip()]
            return [value.strip()] if value.strip() else []
        elif isinstance(value, (list, tuple)):
            return [str(v) for v in value if v]
        else:
            return [str(value)]
    
    def _force_to_timestamp(self, value, field_name: str):
        """å¼ºåˆ¶è½¬æ¢ä¸ºæ—¶é—´æˆ³"""
        # å¦‚æœå·²ç»æ˜¯æ•°å­—æ—¶é—´æˆ³
        if isinstance(value, (int, float)):
            if value > 2524608000:  # æ¯«ç§’çº§
                return int(value)
            elif value > 946684800:  # ç§’çº§ï¼Œè½¬ä¸ºæ¯«ç§’çº§
                return int(value * 1000)
            else:
                self.logger.warning(f"å­—æ®µ '{field_name}': æ•°å­— {value} ä¸åœ¨æœ‰æ•ˆæ—¶é—´æˆ³èŒƒå›´å†…")
                return None
        
        if isinstance(value, str):
            str_val = value.strip()
            
            # å¤„ç†çº¯æ•°å­—å­—ç¬¦ä¸²æ—¶é—´æˆ³
            if str_val.isdigit():
                return self._force_to_timestamp(int(str_val), field_name)
            
            # å¤„ç†å¸¸è§çš„éæ—¥æœŸè¡¨ç¤º
            if str_val.lower() in ['null', 'n/a', 'na', 'æ— ', 'ç©º', 'å¾…å®š', 'tbd']:
                return None
            
            # å°è¯•è§£æå„ç§æ—¥æœŸæ ¼å¼
            date_formats = [
                '%Y-%m-%d %H:%M:%S',
                '%Y-%m-%d',
                '%Y/%m/%d %H:%M:%S',
                '%Y/%m/%d',
                '%m/%d/%Y',
                '%d/%m/%Y',
                '%Yå¹´%mæœˆ%dæ—¥',
                '%mæœˆ%dæ—¥',
                '%Y-%m-%d %H:%M',
                '%Y/%m/%d %H:%M'
            ]
            
            for fmt in date_formats:
                try:
                    dt_obj = dt.datetime.strptime(str_val, fmt)
                    return int(dt_obj.timestamp() * 1000)
                except ValueError:
                    continue
            
            # å¦‚æœéƒ½è§£æå¤±è´¥ï¼Œè®°å½•è­¦å‘Š
            self.logger.warning(f"å­—æ®µ '{field_name}': æ— æ³•è§£ææ—¥æœŸæ ¼å¼ '{value}'ï¼Œå°†å¿½ç•¥æ­¤å€¼")
            return None
        
        # å¤„ç†pandasæ—¶é—´æˆ³
        if hasattr(value, 'timestamp'):
            return int(value.timestamp() * 1000)
        
        self.logger.warning(f"å­—æ®µ '{field_name}': æ— æ³•å°† {type(value).__name__} '{value}' è½¬æ¢ä¸ºæ—¶é—´æˆ³")
        return None
    
    def _force_to_boolean(self, value, field_name: str):
        """å¼ºåˆ¶è½¬æ¢ä¸ºå¸ƒå°”å€¼"""
        if isinstance(value, bool):
            return value
        
        if isinstance(value, (int, float)):
            return bool(value)
        
        if isinstance(value, str):
            str_val = value.strip().lower()
            
            # çœŸå€¼æ˜ å°„
            true_values = ['true', 'æ˜¯', 'yes', '1', 'on', 'checked', 'å¯¹', 'æ­£ç¡®', 'ok', 'y']
            # å‡å€¼æ˜ å°„
            false_values = ['false', 'å¦', 'no', '0', 'off', 'unchecked', '', 'é”™', 'é”™è¯¯', 'n']
            
            if str_val in true_values:
                return True
            elif str_val in false_values:
                return False
            else:
                # å¦‚æœæ— æ³•è¯†åˆ«ï¼ŒæŒ‰å†…å®¹é•¿åº¦åˆ¤æ–­ï¼ˆéç©ºä¸ºçœŸï¼‰
                result = len(str_val) > 0
                self.logger.warning(f"å­—æ®µ '{field_name}': æ— æ³•è¯†åˆ«å¸ƒå°”å€¼ '{value}'ï¼ŒæŒ‰éç©ºè§„åˆ™è½¬æ¢ä¸º {result}")
                return result
        
        # å…¶ä»–ç±»å‹æŒ‰Pythonçš„bool()è§„åˆ™è½¬æ¢
        return bool(value)

    def smart_convert_value(self, value):
        """æ™ºèƒ½è½¬æ¢æ•°å€¼ç±»å‹ï¼ˆå½“æ²¡æœ‰å­—æ®µç±»å‹ä¿¡æ¯æ—¶ï¼‰"""
        if isinstance(value, bool):
            return value
        elif isinstance(value, (int, float)):
            return value
        elif isinstance(value, str):
            str_val = value.strip().lower()
            # å¸ƒå°”å€¼æ£€æµ‹
            if str_val in ['true', 'æ˜¯', 'yes', '1']:
                return True
            elif str_val in ['false', 'å¦', 'no', '0']:
                return False
            # æ•°å­—æ£€æµ‹
            try:
                if '.' in str_val:
                    return float(str_val)
                return int(str_val)
            except (ValueError, TypeError):
                pass
            # æ—¥æœŸæ£€æµ‹ï¼ˆç®€å•çš„æ—¶é—´æˆ³æ£€æµ‹ï¼‰
            if str_val.isdigit() and len(str_val) >= 10:
                try:
                    timestamp = int(str_val)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯åˆç†çš„æ—¶é—´æˆ³èŒƒå›´ï¼ˆ2000å¹´åˆ°2050å¹´ï¼‰
                    if 946684800000 <= timestamp <= 2524608000000:  # æ¯«ç§’çº§æ—¶é—´æˆ³
                        return timestamp
                    elif 946684800 <= timestamp <= 2524608000:  # ç§’çº§æ—¶é—´æˆ³ï¼Œè½¬ä¸ºæ¯«ç§’
                        return timestamp * 1000
                except (ValueError, TypeError):
                    pass
        return str(value)
    
    def simple_convert_value(self, value):
        """ç®€å•è½¬æ¢æ•°å€¼ç±»å‹ï¼ˆç”µå­è¡¨æ ¼æ¨¡å¼ï¼‰"""
        if pd.isnull(value):
            return ""
        else:
            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æˆ–åŸºæœ¬ç±»å‹
            if isinstance(value, (int, float)):
                return value
            elif isinstance(value, bool):
                return value
            else:
                return str(value)
    
    # ========== å¤æ‚å­—æ®µç±»å‹è½¬æ¢ï¼ˆå¤šç»´è¡¨æ ¼ä¸“ç”¨ï¼‰ ==========
    
    def convert_to_user_field(self, value):
        """è½¬æ¢ä¸ºäººå‘˜å­—æ®µæ ¼å¼"""
        if pd.isnull(value) or not value:
            return None
        
        # å¦‚æœå·²ç»æ˜¯æ­£ç¡®çš„å­—å…¸æ ¼å¼
        if isinstance(value, dict) and 'id' in value:
            return [value]
        elif isinstance(value, list):
            # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œæ£€æŸ¥æ¯ä¸ªå…ƒç´ 
            result = []
            for item in value:
                if isinstance(item, dict) and 'id' in item:
                    result.append(item)
                elif isinstance(item, str) and item.strip():
                    result.append({"id": item.strip()})
            return result if result else None
        elif isinstance(value, str):
            # å­—ç¬¦ä¸²æ ¼å¼ï¼Œå¯èƒ½æ˜¯ç”¨æˆ·IDæˆ–å¤šä¸ªç”¨æˆ·IDç”¨åˆ†éš”ç¬¦åˆ†å¼€
            user_ids = []
            if ',' in value:
                user_ids = [uid.strip() for uid in value.split(',') if uid.strip()]
            elif ';' in value:
                user_ids = [uid.strip() for uid in value.split(';') if uid.strip()]
            else:
                user_ids = [value.strip()] if value.strip() else []
            
            return [{"id": uid} for uid in user_ids] if user_ids else None
        
        return None
    
    def convert_to_url_field(self, value):
        """è½¬æ¢ä¸ºè¶…é“¾æ¥å­—æ®µæ ¼å¼"""
        if pd.isnull(value) or not value:
            return None
        
        # å¦‚æœå·²ç»æ˜¯æ­£ç¡®çš„å­—å…¸æ ¼å¼
        if isinstance(value, dict) and 'link' in value:
            return value
        elif isinstance(value, str):
            # ç®€å•URLå­—ç¬¦ä¸²
            url_str = value.strip()
            if url_str.startswith(('http://', 'https://')):
                return {
                    "text": url_str,
                    "link": url_str
                }
            else:
                # ä¸æ˜¯æœ‰æ•ˆURLï¼Œä½œä¸ºæ–‡æœ¬å¤„ç†
                return str(value)
        
        return str(value)
    
    def convert_to_attachment_field(self, value):
        """è½¬æ¢ä¸ºé™„ä»¶å­—æ®µæ ¼å¼"""
        if pd.isnull(value) or not value:
            return None
        
        # å¦‚æœå·²ç»æ˜¯æ­£ç¡®çš„å­—å…¸æ ¼å¼
        if isinstance(value, dict) and 'file_token' in value:
            return [value]
        elif isinstance(value, list):
            result = []
            for item in value:
                if isinstance(item, dict) and 'file_token' in item:
                    result.append(item)
                elif isinstance(item, str) and item.strip():
                    result.append({"file_token": item.strip()})
            return result if result else None
        elif isinstance(value, str):
            # å­—ç¬¦ä¸²æ ¼å¼ï¼Œå¯èƒ½æ˜¯file_token
            token = value.strip()
            return [{"file_token": token}] if token else None
        
        return None
    
    def convert_to_link_field(self, value):
        """è½¬æ¢ä¸ºå…³è”å­—æ®µæ ¼å¼"""
        if pd.isnull(value) or not value:
            return None
        
        # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨æ ¼å¼
        if isinstance(value, list):
            return [str(item) for item in value if item]
        elif isinstance(value, str):
            # å­—ç¬¦ä¸²æ ¼å¼ï¼Œå¯èƒ½æ˜¯record_idæˆ–å¤šä¸ªrecord_idç”¨åˆ†éš”ç¬¦åˆ†å¼€
            record_ids = []
            if ',' in value:
                record_ids = [rid.strip() for rid in value.split(',') if rid.strip()]
            elif ';' in value:
                record_ids = [rid.strip() for rid in value.split(';') if rid.strip()]
            else:
                record_ids = [value.strip()] if value.strip() else []
            
            return record_ids if record_ids else None
        
        return [str(value)] if value else None

    # ========== ç”µå­è¡¨æ ¼è½¬æ¢æ–¹æ³• ==========
    
    def build_data_index(self, df: pd.DataFrame, index_column: Optional[str]) -> Dict[str, int]:
        """æ„å»ºç”µå­è¡¨æ ¼æ•°æ®ç´¢å¼•ï¼ˆå“ˆå¸Œ -> è¡Œå·ï¼‰"""
        index = {}
        if not index_column:
            return index
        
        for idx, row in df.iterrows():
            index_hash = self.get_index_value_hash(row, index_column)
            if index_hash:
                index[index_hash] = idx
        
        return index
    
    def column_number_to_letter(self, col_num: int) -> str:
        """å°†åˆ—å·è½¬æ¢ä¸ºå­—æ¯ï¼ˆ1->A, 2->B, ..., 26->Z, 27->AAï¼‰"""
        result = ""
        while col_num > 0:
            col_num -= 1
            result = chr(65 + col_num % 26) + result
            col_num //= 26
        return result
    
    def column_letter_to_number(self, col_letter: str) -> int:
        """å°†åˆ—å­—æ¯è½¬æ¢ä¸ºæ•°å­—ï¼ˆA->1, B->2, ..., Z->26, AA->27ï¼‰"""
        result = 0
        for char in col_letter:
            result = result * 26 + (ord(char) - ord('A') + 1)
        return result
    
    def df_to_values(self, df: pd.DataFrame, include_headers: bool = True, 
                     selected_columns: Optional[List[str]] = None) -> List[List[Any]]:
        """å°†DataFrameè½¬æ¢ä¸ºç”µå­è¡¨æ ¼å€¼æ ¼å¼ï¼Œæ”¯æŒåˆ—è¿‡æ»¤"""
        values = []
        
        # åº”ç”¨åˆ—è¿‡æ»¤
        if selected_columns:
            # éªŒè¯åˆ—æ˜¯å¦å­˜åœ¨
            valid_columns = [col for col in selected_columns if col in df.columns]
            if len(valid_columns) != len(selected_columns):
                missing = [col for col in selected_columns if col not in df.columns]
                self.logger.warning(f"æŒ‡å®šçš„åˆ—ä¸å­˜åœ¨: {missing}")
            df = df[valid_columns] if valid_columns else df
        
        # æ·»åŠ è¡¨å¤´
        if include_headers:
            values.append(df.columns.tolist())
        
        # æ·»åŠ æ•°æ®è¡Œ
        for _, row in df.iterrows():
            row_values = []
            for value in row:
                converted_value = self.simple_convert_value(value)
                row_values.append(converted_value)
            values.append(row_values)
        
        return values
    
    def df_to_column_data(self, df: pd.DataFrame, selected_columns: Optional[List[str]] = None) -> Dict[str, List[Any]]:
        """å°†DataFrameè½¬æ¢ä¸ºæŒ‰åˆ—ç»„ç»‡çš„æ•°æ®å­—å…¸ï¼Œç”¨äºé€‰æ‹©æ€§åˆ—æ“ä½œ"""
        # åº”ç”¨åˆ—è¿‡æ»¤
        if selected_columns:
            valid_columns = [col for col in selected_columns if col in df.columns]
            if len(valid_columns) != len(selected_columns):
                missing = [col for col in selected_columns if col not in df.columns]
                self.logger.warning(f"æŒ‡å®šçš„åˆ—ä¸å­˜åœ¨: {missing}")
            df = df[valid_columns] if valid_columns else df
        
        column_data = {}
        for col in df.columns:
            # ä¿®å¤ï¼šä¸åº”åŒ…å«è¡¨å¤´ï¼ŒåªåŒ…å«æ•°æ®
            col_values = []
            # æ·»åŠ æ•°æ®
            for value in df[col]:
                converted_value = self.simple_convert_value(value)
                col_values.append(converted_value)
            column_data[col] = col_values
        
        return column_data
    
    def get_column_positions(self, df: pd.DataFrame, selected_columns: Optional[List[str]] = None) -> Dict[str, int]:
        """è·å–åˆ—åœ¨åŸå§‹DataFrameä¸­çš„ä½ç½®æ˜ å°„ï¼ˆ1-basedï¼‰"""
        if selected_columns:
            valid_columns = [col for col in selected_columns if col in df.columns]
        else:
            valid_columns = df.columns.tolist()
        
        positions = {}
        for col in valid_columns:
            # åœ¨å®Œæ•´DataFrameä¸­çš„ä½ç½®ï¼ˆ1-basedï¼‰
            positions[col] = df.columns.get_loc(col) + 1
        
        return positions
    
    def values_to_df(self, values: List[List[Any]]) -> pd.DataFrame:
        """å°†ç”µå­è¡¨æ ¼å€¼æ ¼å¼è½¬æ¢ä¸ºDataFrame"""
        if not values:
            return pd.DataFrame()
        
        # æ¸…ç†æ•°æ®ï¼šç§»é™¤å®Œå…¨ç©ºçš„è¡Œå’Œåˆ—
        cleaned_values = []
        for row in values:
            # ç§»é™¤è¡Œå°¾çš„ç©ºå€¼
            while row and (row[-1] is None or row[-1] == '' or str(row[-1]).strip() == ''):
                row = row[:-1]
            # å¦‚æœè¡Œä¸ä¸ºç©ºï¼Œåˆ™ä¿ç•™
            if row and any(cell is not None and str(cell).strip() != '' for cell in row):
                cleaned_values.append(row)
        
        if not cleaned_values:
            return pd.DataFrame()
        
        # ç¬¬ä¸€è¡Œä½œä¸ºè¡¨å¤´
        headers = cleaned_values[0] if cleaned_values else []
        data_rows = cleaned_values[1:] if len(cleaned_values) > 1 else []
        
        # æ¸…ç†è¡¨å¤´ï¼šç§»é™¤ç©ºçš„åˆ—å
        valid_headers = []
        valid_col_indices = []
        for i, header in enumerate(headers):
            if header is not None and str(header).strip() != '':
                valid_headers.append(str(header).strip())
                valid_col_indices.append(i)
        
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„è¡¨å¤´ï¼Œè¿”å›ç©ºDataFrame
        if not valid_headers:
            return pd.DataFrame()
        
        # æ¸…ç†æ•°æ®è¡Œï¼šåªä¿ç•™æœ‰æ•ˆåˆ—çš„æ•°æ®
        cleaned_data_rows = []
        for row in data_rows:
            cleaned_row = []
            for i in valid_col_indices:
                if i < len(row):
                    cleaned_row.append(row[i])
                else:
                    cleaned_row.append(None)
            cleaned_data_rows.append(cleaned_row)
        
        # åˆ›å»ºDataFrame
        if cleaned_data_rows:
            df = pd.DataFrame(cleaned_data_rows, columns=valid_headers)
        else:
            df = pd.DataFrame(columns=valid_headers)
        
        return df
    
    def get_range_string(self, sheet_id: str, start_row: int, start_col: str, end_row: int, end_col: str) -> str:
        """ç”ŸæˆèŒƒå›´å­—ç¬¦ä¸²"""
        return f"{sheet_id}!{start_col}{start_row}:{end_col}{end_row}"

    # ========== ç»Ÿä¸€æ¥å£æ–¹æ³• ==========
    
    def df_to_records(self, df: pd.DataFrame, field_types: Optional[Dict[str, int]] = None) -> List[Dict]:
        """å°†DataFrameè½¬æ¢ä¸ºé£ä¹¦è®°å½•æ ¼å¼ï¼ˆå¤šç»´è¡¨æ ¼æ¨¡å¼ï¼‰"""
        if self.target_type != TargetType.BITABLE:
            raise ValueError("df_to_records åªæ”¯æŒå¤šç»´è¡¨æ ¼æ¨¡å¼")
        
        records = []
        for _, row in df.iterrows():
            fields = {}
            for k, v in row.to_dict().items():
                if pd.notnull(v):
                    converted_value = self.convert_field_value_safe(str(k), v, field_types)
                    if converted_value is not None:
                        fields[str(k)] = converted_value
            
            record = {"fields": fields}
            records.append(record)
        return records
    
    def report_conversion_stats(self):
        """è¾“å‡ºæ•°æ®è½¬æ¢ç»Ÿè®¡æŠ¥å‘Š"""
        total_conversions = self.conversion_stats['success'] + self.conversion_stats['failed']
        
        if total_conversions > 0:
            success_rate = (self.conversion_stats['success'] / total_conversions) * 100
            
            self.logger.info("=" * 60)
            self.logger.info("ğŸ”„ æ•°æ®ç±»å‹è½¬æ¢ç»Ÿè®¡æŠ¥å‘Š")
            self.logger.info("=" * 60)
            self.logger.info(f"ğŸ“Š æ€»è½¬æ¢æ¬¡æ•°: {total_conversions}")
            self.logger.info(f"âœ… æˆåŠŸè½¬æ¢: {self.conversion_stats['success']} ({success_rate:.1f}%)")
            self.logger.info(f"âŒ å¤±è´¥è½¬æ¢: {self.conversion_stats['failed']}")
            
            if self.conversion_stats['failed'] > 0:
                failure_rate = (self.conversion_stats['failed'] / total_conversions) * 100
                self.logger.warning(f"å¤±è´¥ç‡: {failure_rate:.1f}%")
            
            if self.conversion_stats['warnings']:
                warning_count = len(self.conversion_stats['warnings'])
                self.logger.info(f"âš ï¸  è­¦å‘Šæ•°é‡: {warning_count}")
                
                # å»é‡å¹¶ç»Ÿè®¡ç›¸åŒè­¦å‘Šçš„æ•°é‡
                warning_counts = {}
                for warning in self.conversion_stats['warnings']:
                    warning_counts[warning] = warning_counts.get(warning, 0) + 1
                
                self.logger.info("\nâš ï¸  æ•°æ®è½¬æ¢è­¦å‘Šè¯¦æƒ…:")
                for warning, count in warning_counts.items():
                    self.logger.warning(f"  [{count}æ¬¡] {warning}")
            
            self.logger.info("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            if success_rate < 90:
                self.logger.info("1. æ•°æ®è´¨é‡è¾ƒä½ï¼Œå»ºè®®æ¸…ç†Excelæ•°æ®")
                self.logger.info("2. æ£€æŸ¥æ•°æ®æ ¼å¼æ˜¯å¦æ ‡å‡†åŒ–")
            if self.conversion_stats['failed'] > 0:
                self.logger.info("3. æŸ¥çœ‹ä¸Šè¿°è­¦å‘Šï¼Œè°ƒæ•´æ•°æ®æ ¼å¼æˆ–é£ä¹¦å­—æ®µç±»å‹")
                self.logger.info("4. å¯¹äºæ— æ³•è½¬æ¢çš„å­—æ®µï¼Œè€ƒè™‘ä½¿ç”¨æ–‡æœ¬ç±»å‹")
            
            self.logger.info("\nğŸ“‹ å­—æ®µç±»å‹è½¬æ¢è§„åˆ™:")
            if self.target_type == TargetType.BITABLE:
                self.logger.info("â€¢ æ•°å­—å­—æ®µ: è‡ªåŠ¨æå–æ•°å€¼ï¼Œæ¸…ç†è´§å¸ç¬¦å·å’Œåƒåˆ†ä½")
                self.logger.info("â€¢ å•é€‰å­—æ®µ: å¤šå€¼æ—¶è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ª")
                self.logger.info("â€¢ å¤šé€‰å­—æ®µ: æ”¯æŒé€—å·ã€åˆ†å·ã€ç«–çº¿åˆ†éš”")
                self.logger.info("â€¢ æ—¥æœŸå­—æ®µ: æ”¯æŒå¤šç§æ—¥æœŸæ ¼å¼è‡ªåŠ¨è¯†åˆ«")
                self.logger.info("â€¢ å¸ƒå°”å­—æ®µ: æ™ºèƒ½è¯†åˆ«æ˜¯/å¦ã€true/falseç­‰")
            else:
                self.logger.info("â€¢ ç”µå­è¡¨æ ¼æ¨¡å¼: ä¿æŒåŸå§‹æ•°æ®ç±»å‹ï¼Œç®€å•è½¬æ¢")
            
            self.logger.info("=" * 60)
        else:
            self.logger.info("ğŸ“Š æ²¡æœ‰è¿›è¡Œæ•°æ®ç±»å‹è½¬æ¢")
    
    def generate_sheet_field_config(self, df: pd.DataFrame, strategy: str = 'base', 
                                   config = None) -> Dict[str, Any]:
        """
        ä¸ºç”µå­è¡¨æ ¼ç”Ÿæˆæ™ºèƒ½å­—æ®µé…ç½®
        
        Args:
            df: Excelæ•°æ®
            strategy: å­—æ®µç±»å‹ç­–ç•¥
            config: é…ç½®å¯¹è±¡
            
        Returns:
            å­—æ®µé…ç½®å­—å…¸ {
                'dropdown_configs': [{'column': 'A', 'options': [...], 'colors': [...]}],
                'date_columns': ['B', 'C'],
                'number_columns': ['D', 'E']
            }
        """
        field_config = {
            'dropdown_configs': [],
            'date_columns': [],
            'number_columns': []
        }
        
        for column_name in df.columns:
            # åˆ†ææ¯åˆ—æ•°æ®
            analysis = self.analyze_excel_column_data_enhanced(df, column_name, strategy, config)
            
            # æ ¹æ®åˆ†æç»“æœç”Ÿæˆé…ç½®
            if analysis['suggested_feishu_type'] == 3:  # å•é€‰
                # ç”Ÿæˆä¸‹æ‹‰åˆ—è¡¨é…ç½®
                unique_values = list(set(str(v) for v in df[column_name].dropna()))
                if len(unique_values) <= 20:  # åˆç†çš„é€‰é¡¹æ•°é‡
                    colors = self._generate_option_colors(unique_values)
                    field_config['dropdown_configs'].append({
                        'column': column_name,
                        'options': unique_values,
                        'colors': colors,
                        'multiple': False
                    })
            elif analysis['suggested_feishu_type'] == 4:  # å¤šé€‰
                # ç”Ÿæˆå¤šé€‰ä¸‹æ‹‰åˆ—è¡¨é…ç½®
                all_options = set()
                for value in df[column_name].dropna():
                    value_str = str(value)
                    # æŒ‰åˆ†éš”ç¬¦æ‹†åˆ†
                    for sep in [',', ';', '|']:
                        if sep in value_str:
                            all_options.update(opt.strip() for opt in value_str.split(sep))
                            break
                    else:
                        all_options.add(value_str)
                
                if len(all_options) <= 30:  # å¤šé€‰å…è®¸æ›´å¤šé€‰é¡¹
                    colors = self._generate_option_colors(list(all_options))
                    field_config['dropdown_configs'].append({
                        'column': column_name,
                        'options': list(all_options),
                        'colors': colors,
                        'multiple': True
                    })
            elif analysis['suggested_feishu_type'] == 5:  # æ—¥æœŸ
                field_config['date_columns'].append(column_name)
            elif analysis['suggested_feishu_type'] == 2:  # æ•°å­—
                field_config['number_columns'].append(column_name)
        
        return field_config
    
    def _generate_option_colors(self, options: List[str]) -> List[str]:
        """
        ä¸ºä¸‹æ‹‰åˆ—è¡¨é€‰é¡¹ç”Ÿæˆé¢œè‰²
        
        Args:
            options: é€‰é¡¹åˆ—è¡¨
            
        Returns:
            é¢œè‰²åˆ—è¡¨
        """
        # é¢„å®šä¹‰çš„é¢œè‰²é›†åˆ
        color_palette = [
            "#1FB6C1",  # æµ…è“è‰²
            "#F006C2",  # ç«çº¢è‰²
            "#FB16C3",  # ç²‰çº¢è‰²
            "#FFB6C1",  # æ·¡ç²‰è‰²
            "#32CD32",  # ç»¿è‰²
            "#FF6347",  # ç•ªèŒ„è‰²
            "#9370DB",  # ç´«è‰²
            "#FFD700",  # é‡‘è‰²
            "#FF8C00",  # æ©™è‰²
            "#20B2AA",  # é’è‰²
            "#9400D3",  # æ·±ç´«è‰²
            "#FF1493",  # æ·±ç²‰è‰²
            "#00CED1",  # æ·±ç»¿æ¾çŸ³è‰²
            "#FF69B4",  # çƒ­ç²‰è‰²
            "#8A2BE2",  # è“ç´«è‰²
        ]
        
        # å¾ªç¯ä½¿ç”¨é¢œè‰²
        colors = []
        for i, option in enumerate(options):
            colors.append(color_palette[i % len(color_palette)])
        
        return colors